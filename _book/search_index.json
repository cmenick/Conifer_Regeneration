[["index.html", "Post-Fire Conifer Regeneration Part 1 About", " Post-Fire Conifer Regeneration Casey Menick 2023-04-18 Part 1 About There has been an increasing number of large, high-severity wildfires across the Western United States. It is not fully understood how this intensification may impact conifer forests of the West, whose resilience is dependent on successful seedling regeneration. It is important to understand how these conifer-dominated forests are able to recolonize high-severity burn patches and subsequently respond to these shifting disturbance regimes. The goal of this research is to characterize patterns of conifer recolonization within high-severity burn patches over a 30-year study period. We investigated 34 high-severity wildfire complexes that occurred between 1988 and 1991 in conifer-dominated ecosystems of the northern Rocky Mountains. Composite snow-cover Landsat imagery was utilized to isolate conifer-specific vegetation by diminishing spectral contributions from deciduous vegetation. Conifer regeneration was determined to be detectable by Landsat approximately 11-19 years post-fire and at &gt;10% canopy cover using these methods. The trajectory of snow-cover Landsat NDVI was utilized to estimate recovery time to pre-fire conifer vegetation for lodgepole pine (29.5 years), Douglas-fir (36.9 years), and fir-spruce forest (48.7 years). The presence of conifer regeneration was then modeled at 3-year intervals post-fire to characterize the progression of recolonization. Conifer reoccupancy analysis showed that 65% of the total high-severity burn area was reforested after 30 years. Across all high-severity patches, median patch reoccupancy was 100% within lodgepole pine, 91.1% within Douglas-fir, and 41.3% within fir-spruce. While we identified overall patterns of conifer resilience, we identified lower probabilities of 30-year conifer recovery within low-edge patches, drier climates, and fir-spruce forests. These findings have implications for potential reduced resilience due to climate change and may be applied to support forest restoration decision-making following high-severity wildfire. Additional future analyses should be conducted using snow-cover remote sensing imagery to identify patterns of post-disturbance conifer recovery over a wider spatial and temporal extent. "],["fire-selection.html", "Part 2 Fire Selection 2.1 Set Up 2.2 Define Fire Parameters 2.3 Final Fire Dataset 2.4 Export Data 2.5 Mapping Potential High-Severity Fires 2.6 Mapping Final High-Severity Fires", " Part 2 Fire Selection 2.1 Set Up 2.1.1 Libraries library(tidyverse) library(terra) library(sf) library(mapview) library(raster) library(rgeos) library(lubridate) library(ggplot2) library(exactextractr) library(gridExtra) library(knitr) library(rasterVis) library(RColorBrewer) library(spData) library(forcats) library(cowplot) library(rgeos) 2.1.2 USDA National Forest Type Group Dataset Conifer Forest Type Groups: Douglas-Fir, Fir-Spruce-Mountain Hemlock, Lodgepole Pine # forest type groups and key conus_forestgroup &lt;- raster(&#39;data/forest_type/conus_forestgroup.tif&#39;) forest_codes &lt;- read_csv(&#39;data/forest_type/forestgroupcodes.csv&#39;) # set crs crs = crs(conus_forestgroup) 2.1.3 EPA level-3 Ecoregions Canadian Rockies, Idaho Batholith, Middle Rockies, Columbian Mountains - Northern Rockies # level 3 ecoregions l3eco &lt;- st_read(&#39;data/ecoregion/us_eco_l3.shp&#39;) %&gt;% st_transform(., crs=crs) # select northern rocky mountains from level3 ecoregions eco_select &lt;- l3eco %&gt;% filter(NA_L3NAME %in% c(&#39;Canadian Rockies&#39;,&#39;Columbia Mountains/Northern Rockies&#39;,&#39;Middle Rockies&#39;,&#39;Idaho Batholith&#39;)) 2.1.4 Mapping 2.1.4.1 Ecoregions # mapview palette &lt;- brewer.pal(18,&quot;YlGn&quot;) palette[1] &lt;- rgb(255, 255, 255, maxColorValue=255, alpha=1) mapview(eco_select,na.color=palette[1],zcol = &quot;US_L3NAME&quot;,layer.name = &quot;Level-3 Ecoregion&quot;, legend=TRUE) 2.1.4.2 Forest Type Groups # convert raster values to factors forestgroup_eco &lt;- crop(conus_forestgroup,eco_select) %&gt;% mask(.,eco_select) forestgroup_eco[forestgroup_eco %in% c(120,180,240,300,320, 360, 370, 400, 500,700,900,920,950)] &lt;- 1 # add a labels for forest type code group_levels &lt;- levels(forestgroup_eco %&gt;% as.factor())[[1]] group_levels[[&quot;Forest Type&quot;]] &lt;- c(&quot;Unforested&quot;,&quot;Other&quot;,&quot;200: Douglas-fir&quot;,&quot;220: Ponderosa Pine&quot;,&quot;260: Fir/Spruce/Mountain Hemlock&quot;,&quot;280: Lodgepole Pine&quot;) # group_levels[[&quot;forest_type&quot;]] &lt;- c(&quot;Unforested&quot;,&quot;120: Spruce/Fir&quot;,&quot;180: Pinyon/Juniper&quot;,&quot;200: Douglas-fir&quot;,&quot;220: Ponderosa Pine&quot;,&quot;240: Western White Pine&quot;,&quot;260: Fir/Spruce/Mountain Hemlock&quot;,&quot;280: Lodgepole Pine&quot;,&quot;300: Hemlock/Sitka Spruce&quot;,&quot;320: Western Larch&quot;,&quot;360: Other Western Softwood&quot;,&quot;370: California Mixed Conifer&quot;,&quot;400: Oak/Pine&quot;,&quot;500: Oak/Hickory&quot;,&quot;700: Elm/Ash/Cottonwood&quot;,&quot;900: Aspen/Birch&quot;,&quot;920: Western Oak&quot;) levels(forestgroup_eco) &lt;- group_levels # mapview mapview(forestgroup_eco, col.regions=palette,na.color=palette[1],legend=TRUE,layer.name = &quot;Forest Type&quot;) 2.2 Define Fire Parameters 2.2.1 Monitoring Trends in Burn Severity (MTBS) Dataset # import mtbs fire perimeters mtbs_full &lt;- st_read(&#39;data/mtbs/mtbs_perims_DD.shp&#39;) %&gt;% st_transform(., crs=crs) # filter mtbs data to area and timepoints of interest mtbs_select &lt;- mtbs_full %&gt;% mutate(state = str_sub(Event_ID,0,2), year = year(as.Date(Ig_Date))) %&gt;% filter(state %in% c(&quot;WA&quot;,&quot;ID&quot;,&quot;MT&quot;,&quot;WY&quot;,&quot;SD&quot;), between(Ig_Date, as.Date(&#39;1988-01-1&#39;), as.Date(&#39;1991-12-31&#39;))) 2.2.2 Group Adjacent Fires # function to group adjoining fire polygons to ensure contiguous high-severity patches across MTBS events group_fires &lt;- function(mtbs_year) { # join the polygons with themselves, and remove those that do not join with any besides themselves combined&lt;- st_join(mtbs_year, mtbs_year, join=st_is_within_distance, dist = 180, left = TRUE,remove_self = TRUE) %&gt;% drop_na(Event_ID.y)%&gt;% dplyr::select(Event_ID.x,Event_ID.y) if(nrow(combined)&gt;=1){ # if there are overlaps for this years fires... # partition data into that that has overlap, and that that does not overlap &lt;- mtbs_year %&gt;% filter(Event_ID %in% combined$Event_ID.x) no_overlap &lt;- mtbs_year %&gt;% filter(!(Event_ID %in% combined$Event_ID.x)) print(paste0(&quot;there are &quot;,nrow(overlap),&quot; overlapping polygons&quot;)) # join all overlapping features, and buffer to ensure proper grouping overlap_union &lt;- st_union(overlap) %&gt;% st_buffer(190) # break apart the joined polygons into their individual groups groups &lt;- st_as_sf(st_cast(overlap_union ,to=&#39;POLYGON&#39;,group_or_split=TRUE)) %&gt;% mutate(year = mean(mtbs_year$year), Fire_ID = str_c(&quot;Fire_&quot;,c(1:nrow(.)),&quot;_&quot;,year)) %&gt;% rename(geometry = x) print(paste0(&quot;polygons formed into &quot;,nrow(groups),&quot; groups&quot;)) # join back with original dataset to return to unbuffered geometry grouped_overlap &lt;- st_join(overlap,groups,left=TRUE) # arrange by the new grouping joined_overlap_groups &lt;- grouped_overlap %&gt;% group_by(Fire_ID) %&gt;% tally()%&gt;% st_buffer(1) %&gt;% dplyr::select(Fire_ID) %&gt;% mutate(year = mean(mtbs_year$year)) # add new ID to the freestanding polygons no_overlap_groups &lt;- no_overlap %&gt;% mutate(Fire_ID = str_c(&quot;Fire_&quot;,nrow(groups)+c(1:nrow(no_overlap)),&quot;_&quot;,year)) %&gt;% dplyr::select(Fire_ID,year) # join the new grouped overlap and the polygons without overlap fires_export &lt;- rbind(joined_overlap_groups,no_overlap_groups) return(fires_export) } else { # if there are no overlaps for this year... print(&quot;no overlapping polygons&quot;) fires_export &lt;- mtbs_year %&gt;% mutate(Fire_ID = str_c(&quot;Fire_&quot;,c(1:nrow(.)),&quot;_&quot;,year)) %&gt;% dplyr::select(Fire_ID,year) return(fires_export) } } # group adjacent polygons within each fire year fires_88 &lt;- group_fires(mtbs_select %&gt;% filter(year == 1988)) ## [1] &quot;there are 22 overlapping polygons&quot; ## [1] &quot;polygons formed into 7 groups&quot; fires_89 &lt;- group_fires(mtbs_select %&gt;% filter(year == 1989)) ## [1] &quot;there are 2 overlapping polygons&quot; ## [1] &quot;polygons formed into 1 groups&quot; fires_90 &lt;- group_fires(mtbs_select %&gt;% filter(year == 1990)) ## [1] &quot;there are 2 overlapping polygons&quot; ## [1] &quot;polygons formed into 1 groups&quot; fires_91 &lt;- group_fires(mtbs_select %&gt;% filter(year == 1991)) ## [1] &quot;no overlapping polygons&quot; # join each fire year mtbs_grouped &lt;- rbind(fires_88,fires_89,fires_90,fires_91)%&gt;% mutate(area_ha = as.numeric(st_area(geometry))/10000, area_acres = area_ha*2.471) 2.2.3 Select Fires by Ecoregion and Forest Type # assign ecoregion and proportions of forest type to each fire polygon fires_join &lt;- st_join(mtbs_grouped,eco_select,join=st_intersects,left=FALSE,largest=TRUE) %&gt;% left_join(., exact_extract(conus_forestgroup,mtbs_grouped, append_cols = TRUE, max_cells_in_memory = 3e+08, fun = function(value, coverage_fraction) { data.frame(value = value, frac = coverage_fraction / sum(coverage_fraction)) %&gt;% group_by(value) %&gt;% summarize(freq = sum(frac), .groups = &#39;drop&#39;) %&gt;% pivot_wider(names_from = &#39;value&#39;, names_prefix = &#39;freq_&#39;, values_from = &#39;freq&#39;)}) %&gt;% mutate(across(starts_with(&#39;freq&#39;), replace_na, 0))) # remove unnecessary columns, cleanup names # filter to ensure fire polygons are at least 25% type of interest fires &lt;- fires_join %&gt;% dplyr::select(&quot;Fire_ID&quot;,&quot;year&quot;,&quot;area_ha&quot;,&quot;area_acres&quot;,&quot;US_L3NAME&quot;,&quot;freq_0&quot;,&quot;freq_200&quot;,&quot;freq_220&quot;,&quot;freq_260&quot;,&quot;freq_280&quot;) %&gt;% rename(&quot;ecoregion&quot; = &quot;US_L3NAME&quot;, &quot;freq_df&quot;=&quot;freq_200&quot;, &quot;freq_pp&quot;=&quot;freq_220&quot;, &quot;freq_fs&quot;=&quot;freq_260&quot;, &quot;freq_lpp&quot;=&quot;freq_280&quot;) %&gt;% mutate(freq_allother = 1-(freq_0 + freq_df+freq_pp+freq_fs+freq_lpp), freq_forested = 1- freq_0, freq_ideal = freq_df+freq_fs+freq_lpp)%&gt;% mutate(across(starts_with(&#39;freq&#39;), round,2))%&gt;% filter(freq_ideal &gt; 0.25) 2.2.4 Select Fires by Burn Severity # import all mtbs rasters via a list rastlist &lt;- list.files(path = &quot;data/mtbs&quot;, pattern=&#39;.tif&#39;, all.files=TRUE, full.names=TRUE) allrasters &lt;- lapply(rastlist, raster) names(allrasters) &lt;- str_c(&quot;y&quot;, str_sub(rastlist,22,25)) # create empty dataframe severity_list &lt;- list() # loop through mtbs mosasics for 1988-1991 # extract mtbs burn severity raster for all selected fires # calculate burn severity percentages for each fire for (i in names(allrasters)){ mtbs_year &lt;- allrasters[[i]] fire_year &lt;- filter(fires, year==str_sub(i,2,5)) raster_extract &lt;- exact_extract(mtbs_year,fire_year, max_cells_in_memory = 3e+09,coverage_area=TRUE) names(raster_extract) &lt;- fire_year$Fire_ID output_select &lt;- bind_rows(raster_extract, .id = &quot;Fire_ID&quot;)%&gt;% group_by(Fire_ID , value) %&gt;% summarize(total_area = sum(coverage_area)) %&gt;% group_by(Fire_ID) %&gt;% mutate(proportion = total_area/sum(total_area))%&gt;% dplyr::select(&quot;Fire_ID&quot;,&quot;value&quot;,&quot;proportion&quot;) %&gt;% spread(.,key=&quot;value&quot;,value = &quot;proportion&quot;) severity_list[[i]] &lt;- output_select } # combine extracted raster datasets severity_df &lt;- do.call(rbind, severity_list) # join burn severity % to fires polygons # filter dataset for 500 acres high severity fires_severity &lt;- left_join(fires,severity_df,by=&quot;Fire_ID&quot;)%&gt;% rename(noburn= &quot;1&quot;,lowsev = &quot;2&quot;, medsev = &quot;3&quot;, highsev = &quot;4&quot;,regrowth = &quot;5&quot;, error = &quot;6&quot;) %&gt;% dplyr::select(- &quot;NaN&quot;,-&quot;regrowth&quot;,-&quot;error&quot;) %&gt;% mutate(highsev_acres = area_acres*highsev)%&gt;% filter(highsev_acres &gt; 500) 2.2.5 Clean Up Dataset # get the most common forest type within each polygon fires_select &lt;- fires_severity %&gt;% left_join(.,exact_extract(conus_forestgroup,fires_severity, &#39;mode&#39;, append_cols = TRUE, max_cells_in_memory = 3e+08)) fires_select$mode &lt;- as.factor(fires_select$mode) fires_select &lt;- fires_select %&gt;% mutate(fire_foresttype = case_when(mode==200 ~ &quot;Douglas-Fir&quot;, mode==220 ~ &quot;Ponderosa&quot;, mode==260 ~ &quot;Fir-Spruce&quot;, mode==280 ~ &quot;Lodegepole Pine&quot;, TRUE ~ &quot;Other&quot;), Fire_ID = str_c(&quot;Fire_&quot;,c(1:nrow(.)),&quot;_&quot;,year)) # join the grouped fires back to original mtbs boundaries fires_mtbs &lt;- st_join(mtbs_select,fires_select,left=FALSE,largest=TRUE) %&gt;% filter(year.x==year.y)%&gt;% dplyr::select(&quot;Event_ID&quot;,&quot;Incid_Name&quot;,&quot;Fire_ID&quot;,&quot;Ig_Date&quot;,&quot;year.y&quot;,&quot;state&quot;,&quot;BurnBndAc&quot;,&quot;ecoregion&quot;) %&gt;% rename(year= year.y) 2.3 Final Fire Dataset 2.3.1 Dataset Overview full_dataset &lt;- fires_select %&gt;% st_drop_geometry() %&gt;% dplyr::select(Fire_ID,year,ecoregion,fire_foresttype,area_acres,highsev) %&gt;% mutate(highsev = round(highsev,2), area_acres = round(area_acres,0)) kable(full_dataset, align = &#39;c&#39;, padding = 1, col.names = c(&quot;Fire ID&quot;, &quot;Year&quot;, &quot;Ecoregion&quot;, &quot;Majority Forest Type&quot;,&quot;Area (acres)&quot;, &quot;High Severity %&quot;), caption = &quot;High-Severity Conifer-Dominated Fires 1988-1991&quot;) Table 2.1: High-Severity Conifer-Dominated Fires 1988-1991 Fire ID Year Ecoregion Majority Forest Type Area (acres) High Severity % Fire_1_1988 1988 Middle Rockies Fir-Spruce 342005 0.27 Fire_2_1988 1988 Middle Rockies Lodegepole Pine 777690 0.28 Fire_3_1988 1988 Middle Rockies Lodegepole Pine 448911 0.21 Fire_4_1988 1988 Idaho Batholith Douglas-Fir 5651 0.16 Fire_5_1988 1988 Idaho Batholith Fir-Spruce 11945 0.23 Fire_6_1988 1988 Idaho Batholith Douglas-Fir 50666 0.07 Fire_7_1988 1988 Middle Rockies Lodegepole Pine 167870 0.50 Fire_8_1988 1988 Idaho Batholith Douglas-Fir 25889 0.02 Fire_9_1988 1988 Idaho Batholith Douglas-Fir 8312 0.17 Fire_10_1988 1988 Canadian Rockies Lodegepole Pine 42492 0.52 Fire_11_1988 1988 Idaho Batholith Fir-Spruce 45075 0.43 Fire_12_1988 1988 Middle Rockies Lodegepole Pine 5633 0.24 Fire_13_1988 1988 Idaho Batholith Douglas-Fir 4962 0.25 Fire_14_1988 1988 Middle Rockies Other 35864 0.46 Fire_15_1988 1988 Idaho Batholith Fir-Spruce 19499 0.29 Fire_16_1988 1988 Idaho Batholith Fir-Spruce 5626 0.09 Fire_17_1988 1988 Idaho Batholith Fir-Spruce 12746 0.40 Fire_18_1988 1988 Middle Rockies Other 13108 0.48 Fire_19_1988 1988 Idaho Batholith Fir-Spruce 7241 0.27 Fire_20_1988 1988 Idaho Batholith Fir-Spruce 6559 0.13 Fire_21_1988 1988 Middle Rockies Fir-Spruce 3113 0.17 Fire_22_1988 1988 Middle Rockies Other 29233 0.16 Fire_23_1988 1988 Middle Rockies Other 1363 0.41 Fire_24_1988 1988 Idaho Batholith Douglas-Fir 48136 0.31 Fire_25_1988 1988 Northern Rockies Douglas-Fir 8089 0.25 Fire_26_1988 1988 Middle Rockies Douglas-Fir 8588 0.56 Fire_27_1988 1988 Northern Rockies Douglas-Fir 11403 0.30 Fire_28_1988 1988 Northern Rockies Douglas-Fir 21854 0.25 Fire_29_1988 1988 Canadian Rockies Douglas-Fir 33844 0.27 Fire_30_1988 1988 Northern Rockies Douglas-Fir 1909 0.31 Fire_31_1988 1988 Middle Rockies Other 6282 0.47 Fire_32_1989 1989 Idaho Batholith Fir-Spruce 13334 0.15 Fire_33_1989 1989 Middle Rockies Lodegepole Pine 3298 0.37 Fire_34_1989 1989 Idaho Batholith Douglas-Fir 4928 0.38 Fire_35_1989 1989 Idaho Batholith Douglas-Fir 47680 0.02 Fire_36_1989 1989 Idaho Batholith Fir-Spruce 2486 0.30 Fire_37_1989 1989 Idaho Batholith Fir-Spruce 5566 0.30 Fire_38_1989 1989 Idaho Batholith Fir-Spruce 7443 0.28 Fire_39_1989 1989 Idaho Batholith Fir-Spruce 6786 0.26 Fire_40_1989 1989 Idaho Batholith Douglas-Fir 8733 0.12 Fire_41_1989 1989 Idaho Batholith Fir-Spruce 1615 0.49 Fire_42_1989 1989 Idaho Batholith Lodegepole Pine 2488 0.33 Fire_43_1989 1989 Idaho Batholith Fir-Spruce 3081 0.27 Fire_44_1990 1990 Middle Rockies Douglas-Fir 2535 0.45 Fire_45_1990 1990 Idaho Batholith Fir-Spruce 3418 0.53 Fire_46_1990 1990 Idaho Batholith Douglas-Fir 2249 0.49 Fire_47_1990 1990 Middle Rockies Lodegepole Pine 2763 0.41 Fire_48_1990 1990 Middle Rockies Other 13461 0.19 Fire_49_1991 1991 Middle Rockies Douglas-Fir 6978 0.31 Fire_50_1991 1991 Middle Rockies Douglas-Fir 3097 0.18 Fire_51_1991 1991 Middle Rockies Fir-Spruce 6995 0.14 Fire_52_1991 1991 Idaho Batholith Douglas-Fir 1186 0.55 Fire_53_1991 1991 Northern Rockies Fir-Spruce 7095 0.39 Fire_54_1991 1991 Northern Rockies Fir-Spruce 2478 0.51 2.4 Export Data 2.4.1 Final Cleanup for Export # reformat and project fires_export &lt;- fires_select %&gt;% mutate(year = as.integer(year)) %&gt;% st_transform(., crs=&quot;EPSG:4326&quot;) mtbs_export &lt;- fires_mtbs %&gt;% mutate(year = as.integer(year)) %&gt;% st_transform(., crs=&quot;EPSG:4326&quot;) 2.4.2 Export # st_write(fires_export, &quot;data/fire_boundaries/&quot;, &quot;fires_export.shp&quot;, driver = &#39;ESRI Shapefile&#39;) # st_write(mtbs_export, &quot;data/fire_boundaries/&quot;, &quot;mbts_export.shp&quot;, driver = &#39;ESRI Shapefile&#39;) 2.5 Mapping Potential High-Severity Fires 2.5.1 Selected fires by year # plot selected fire events by year mapview(fires_select %&gt;% mutate(year = as.factor(year)), zcol = &quot;year&quot;,layer.name = &quot;Fire Year&quot;) + mapview(st_union(eco_select),color = &#39;black&#39;, lwd = 1, alpha.regions = 0) 2.5.2 Selected fires by majority forest type # plot selected fire events by majority forest type mapview(fires_select %&gt;% mutate(fire_foresttype = as.factor(fire_foresttype)), zcol = &quot;fire_foresttype&quot;,layer.name = &quot;Majority Forest Type&quot;) + mapview(st_union(eco_select),color = &#39;black&#39;, lwd = 1, alpha.regions = 0) 2.6 Mapping Final High-Severity Fires 2.6.1 Final Fires # list of final fire events, after filtering to remove reburnt and managed areas fire_names &lt;- c(&quot;Fire_1_1988&quot;,&quot;Fire_2_1988&quot;,&quot;Fire_3_1988&quot;,&quot;Fire_4_1988&quot;,&quot;Fire_7_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_31_1988&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_35_1989&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_42_1989&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_51_1991&quot;,&quot;Fire_54_1991&quot;) 2.6.2 Final Map crs = 4388 states49 &lt;- (us_states[&quot;NAME&quot;])%&gt;% st_transform(3488) borders &lt;- rnaturalearth::ne_states(c(&quot;united states of america&quot;, &quot;canada&quot;)) %&gt;% st_as_sf() eco_border &lt;- st_union(eco_select) %&gt;% st_transform(crs = crs) conus_forestgroup &lt;- rast(&#39;data/forest_type/conus_forestgroup.tif&#39;) forestgroup_map &lt;- crop(conus_forestgroup,st_buffer(eco_select,290000))%&gt;% as.factor() %&gt;% aggregate(fact=3,fun = &quot;modal&quot;) %&gt;% project(.,eco_border) ## |---------|---------|---------|---------| ========================================= forestgroup_df &lt;- as.data.frame(forestgroup_map,xy = T) %&gt;% mutate(ftype = case_when(Red == 0 ~ &quot;Unforested&quot;, Red == 200 ~ &quot;Douglas-Fir&quot;, Red == 220 ~ &quot;Ponderosa Pine&quot;, Red == 280 ~ &quot;Lodgepole Pine&quot;, Red == 260 ~ &quot;Fir-Spruce&quot;, TRUE ~ &quot;Other&quot;)) forestgroup_df$ftype &lt;- fct_relevel(forestgroup_df$ftype , c(&quot;Douglas-Fir&quot;,&quot;Lodgepole Pine&quot;,&quot;Fir-Spruce&quot;,&quot;Ponderosa Pine&quot;, &quot;Other&quot;, &quot;Unforested&quot;)) palette &lt;- brewer.pal(4,&quot;YlGn&quot;) inset &lt;-ggplot() + geom_sf(data = states49 %&gt;% st_transform(crs = crs), fill = NA,color=alpha(&quot;#525258&quot;),lwd=.4) + geom_sf(data = st_union(eco_select) %&gt;% st_transform(crs = crs),color = &quot;black&quot;,fill=&quot;black&quot;,lwd=.4) + theme_bw() + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank()) mainplot &lt;- ggplot() + geom_raster(data = forestgroup_df,aes(x,y,fill=as.factor(ftype)),alpha = .8)+ scale_fill_manual(values = c(&quot;#C3E699&quot;,&quot;#68CE66&quot;,&quot;#238443&quot;,&quot;#8BB62F&quot;,&quot;#D8E895&quot;,&quot;white&quot;))+ geom_sf(data = borders %&gt;% st_transform(crs = crs), fill = NA,color=alpha(&quot;black&quot;,0.14),lwd=.05) + geom_sf(data = fires_select %&gt;% filter(Fire_ID %in% fire_names) %&gt;% st_transform(crs = crs),fill = &quot;black&quot;, color = &quot;black&quot;) + geom_sf(data = st_union(eco_select) %&gt;% st_transform(crs = crs), fill = NA, color=alpha(&quot;black&quot;,0.7),lwd=.4,linetype = &quot;F1&quot;) + scale_x_continuous(limits = c(-119.4952-.5,-103.21640-1.68), expand = c(0, 0)) + scale_y_continuous(limits = c(41.89902-.5,49.00152+.5), expand = c(0, 0)) + labs(fill = &quot;Forest Type&quot;, x = &quot;Longitude&quot;, y = &quot;Latitude&quot;) + theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) ggdraw() + draw_plot(mainplot) + draw_plot(inset, height = 0.2, x = .39, y = 0.15 ) "],["calculation-of-high-severity.html", "Part 3 Calculation of High-Severity 3.1 Set Up 3.2 Imagery 3.3 Burn Indices 3.4 Export Data", " Part 3 Calculation of High-Severity 3.1 Set Up 3.1.1 Import Fire Boundaries var mtbs_all = ee.FeatureCollection(&quot;USFS/GTAC/MTBS/burned_area_boundaries/v1&quot;); var fires = ee.FeatureCollection(&quot;projects/westernconiferregen/assets/fires_export&quot;); 3.1.2 Clean Fire Boundaries // filter mtbs fire perimeters to relevant date range var mtbs = mtbs_all .filter(ee.Filter.gt(&quot;Ig_Date&quot;,ee.Date(&#39;1984-01-01&#39;).millis())) .filter(ee.Filter.lt(&quot;Ig_Date&quot;,ee.Date(&#39;1992-12-31&#39;).millis())); // list fire IDs and get total number of fires var fireID = ee.List(fires.aggregate_array(&#39;Fire_ID&#39;)).getInfo(); var nFires = fireID.length; 3.2 Imagery 3.2.1 Import Landsat 5 // Landsat 5 Surface Reflectance Tier 1 collection var ls5_SR = ee.ImageCollection(&#39;LANDSAT/LT05/C01/T1_SR&#39;); 3.2.2 Prepare Landsat Data // function to get NBR, qa pixel bands var ls5_getbands = function(lsImage){ var nbr = lsImage.normalizedDifference([&#39;B4&#39;, &#39;B7&#39;]).toFloat(); var qa = lsImage.select([&#39;pixel_qa&#39;]); return nbr.addBands([qa]) .select([0,1], [&#39;nbr&#39;, &#39;pixel_qa&#39;]) .copyProperties(lsImage, [&#39;system:time_start&#39;]); }; // function to get clear pixels var ls5_qa = function(lsImg){ var quality =lsImg.select([&#39;pixel_qa&#39;]); var clear = quality.bitwiseAnd(8).eq(0) // cloud shadow .and(quality.bitwiseAnd(32).eq(0) // cloud .and(quality.bitwiseAnd(4).eq(0) // water .and(quality.bitwiseAnd(16).eq(0)))); // snow return lsImg.updateMask(clear).select([0]) .copyProperties(lsImg, [&#39;system:time_start&#39;]); }; // function to project to EPSG 4326 var ls5_project = function(lsImage){ var proj4326 = ee.Projection(&#39;EPSG:4326&#39;).atScale(30); var lsImage_proj = lsImage.reproject(proj4326); return lsImage_proj; }; // Map functions across Landsat Collection var ls5 = ls5_SR.map(ls5_getbands) .map(ls5_qa) .map(ls5_project); 3.3 Burn Indices 3.3.1 Calculate RdNBR // Calculate burn severity metrics for each fire var indices = ee.ImageCollection(fires.map(function(fire){ // get fire bounds var fireBounds = fire.geometry().bounds(); // get pre- and post-fire years var fireYear = ee.Date.parse(&#39;YYYY&#39;, fire.get(&#39;year&#39;)); var preFireYear = fireYear.advance(-1, &#39;year&#39;); var postFireYear = fireYear.advance(1, &#39;year&#39;); // filter ls5 to fire bounds and dates to get pre and post-fire imagery var preNBR = ls5.filterBounds(fireBounds) .filterDate(preFireYear, fireYear) .filter(ee.Filter.dayOfYear(152, 273)) .mean() .rename(&#39;preNBR&#39;); var postNBR = ls5.filterBounds(fireBounds) .filterDate(postFireYear, fireYear.advance(2, &#39;year&#39;)) .filter(ee.Filter.dayOfYear(152, 273)) .mean() .rename(&#39;postNBR&#39;); // calculate sqrt of pre-fire NBR to relativize var preNBRsq = preNBR .expression(&quot;abs(b(&#39;preNBR&#39;)) &lt; 0.001 ? 0.001&quot; + &quot;: b(&#39;preNBR&#39;)&quot;) .abs().sqrt().rename(&#39;preNBRsq&#39;).toFloat(); // combine pre and post-fire imagery var fireIndices = preNBR.addBands(postNBR).addBands(preNBRsq); // calculate dNBR var dnbr = fireIndices.expression(&quot;(b(&#39;preNBR&#39;) - b(&#39;postNBR&#39;)) * 1000&quot;).rename(&#39;dnbr&#39;).toFloat(); // calculate offset value from 180-m buffer of unburned area outside the fire perimeter var ring = fire.buffer(180).difference(mtbs.geometry()); var offset = ee.Image.constant(ee.Number(dnbr.select(&#39;dnbr&#39;).reduceRegion({ reducer: ee.Reducer.mean(), geometry: ring.geometry(), scale: 30, maxPixels: 1e9 }).get(&#39;dnbr&#39;))).rename(&#39;offset&#39;).toFloat().addBands(dnbr); // calculate dNBR with offset var dnbr_w_offset = fireIndices .addBands(offset.expression(&quot;b(&#39;dnbr&#39;) - b(&#39;offset&#39;)&quot;).rename(&#39;dnbr_w_offset&#39;).toFloat()); // calculate RdNBR with offset var rdnbr_w_offset = dnbr_w_offset.expression(&quot;b(&#39;dnbr_w_offset&#39;) / b(&#39;preNBRsq&#39;)&quot;).rename(&#39;rdnbr_w_offset&#39;).toFloat(); return rdnbr_w_offset.select(&#39;rdnbr_w_offset&#39;).set({&#39;fireID&#39;: fire.get(&#39;Fire_ID&#39;),&#39;fireYear&#39;: fire.get(&#39;year&#39;) }); })); 3.4 Export Data 3.4.1 Export Each Fire RdNBR to Drive // export to drive for (var j = 0; j &lt; nFires; j++){ var id = fireID[j]; var Name = id; var fireExport = ee.Image(indices.filterMetadata(&#39;fireID&#39;, &#39;equals&#39;, id).first()); var fireBounds = ee.Feature(fires.filterMetadata(&#39;Fire_ID&#39;, &#39;equals&#39;, id).first()).geometry().bounds(); var firePolygon = ee.Feature(fires.filterMetadata(&#39;Fire_ID&#39;, &#39;equals&#39;, id).first()).geometry(); var exportImg = fireExport.select(&#39;rdnbr_w_offset&#39;).toInt().clip(firePolygon); Export.image.toDrive({ image: exportImg, folder: &quot;fire_rdnbr_rasters&quot;, description: Name, crs: &quot;EPSG:4326&quot;, maxPixels: 1e13, scale: 30, region: fireBounds }); } "],["patch-formation.html", "Part 4 Patch Formation 4.1 Set Up 4.2 Create High-Severity Patches 4.3 Refine Patches 4.4 Mapping 4.5 Export Data", " Part 4 Patch Formation 4.1 Set Up 4.1.1 Libraries library(tidyverse) library(terra) library(patchwoRk) library(sf) library(mapview) library(exactextractr) library(lubridate) 4.1.2 Import RdNBR Rasters # import calculated RdNBR rasters for each fire boundary polygon rast_list &lt;- list.files(path = &quot;data/rdnbr_rasters&quot;, pattern=&#39;.tif&#39;, all.files=TRUE, full.names=TRUE) rast_all &lt;- lapply(rast_list, rast) rast_collection &lt;- sprc(rast_all) crs &lt;- crs(rast_collection[1]) 4.1.3 Import Fire Boundaries # import fire boundaries mtbs_export &lt;- st_read(&#39;data/fire_boundaries/mtbs_export.shp&#39;) %&gt;% st_transform(., crs=crs) fires_export &lt;- st_read(&quot;data/fire_boundaries/fires_export.shp&quot;)%&gt;% st_transform(., crs=crs) # import forest type group raster conus_forestgroup &lt;- raster(&#39;data/forest_type/conus_forestgroup.tif&#39;) forest_codes &lt;- read_csv(&#39;data/forest_type/forestgroupcodes.csv&#39;) 4.2 Create High-Severity Patches 4.2.1 PatchMorph # loop through RdNBR rasters, assign &gt;640 to high severity category # utilize patchmorph to act as 3x3 cell majority filter patch_df &lt;- list() for (i in 1:length(rast_all)){ rast_fire &lt;- raster(rast_collection[i]) rast_fire[rast_fire &lt; 640] &lt;- 0 rast_fire[rast_fire &gt;= 640] &lt;- 1 patch &lt;- patchMorph(rast_fire, spurThresh = 3, gapThresh = 3) patch_poly &lt;- as.polygons(rast(patch)) %&gt;% st_as_sf() df_union_cast &lt;- patch_poly %&gt;% st_cast(., &quot;POLYGON&quot;) %&gt;% filter(layer == 1) patch_df[[i]] &lt;- df_union_cast} patch_poly_all &lt;- do.call(rbind,patch_df) 4.3 Refine Patches # filter small patches patches_full &lt;- patch_poly_all %&gt;% mutate(patch_area_ha = as.numeric(st_area(.))/10000) %&gt;% filter(patch_area_ha &gt; 2.25) # join patches back to grouped fires patches_joined &lt;- st_join(patches_full,mtbs_export,join = st_intersects,left= FALSE,largest = TRUE) %&gt;% dplyr::select(-layer,-BurnBndAc) %&gt;% left_join(.,exact_extract(conus_forestgroup,., &#39;mode&#39;, append_cols = TRUE, max_cells_in_memory = 3e+08))%&gt;% mutate(patch_foresttype = case_when(mode==200 ~ &quot;Douglas-Fir&quot;, mode==220 ~ &quot;Ponderosa&quot;, mode==260 ~ &quot;Fir-Spruce&quot;, mode==280 ~ &quot;Lodegepole Pine&quot;, mode==0 ~ &quot;Unforested&quot;, TRUE ~ &quot;Other&quot;)) 4.4 Mapping mapview(patches_joined,col.regions = &quot;red&quot;,layer.name = &quot;High-severity Burn Patches&quot;) + mapview(fires_export, alpha.regions = 0, lwd = 2,color = &quot;black&quot;,col.regions = &quot;black&quot;, layer.name = &quot;Fire Boundaries&quot;) 4.5 Export Data patches &lt;- patches_joined %&gt;% st_transform(crs = crs) # st_write(patches, &quot;data/patches/&quot;, &quot;highsev_patches.shp&quot;,driver = &#39;ESRI Shapefile&#39;) "],["model-training-quadrants.html", "Part 5 Model Training Quadrants 5.1 Set Up 5.2 Create Sampling Quadrants 5.3 Export Data", " Part 5 Model Training Quadrants 5.1 Set Up 5.1.1 Libraries library(elevatr) library(tidyverse) library(sf) library(terra) library(mapview) 5.1.2 Import High-Severity Patches and Fire Boundaries # data import patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% st_transform(crs=&quot;EPSG:4326&quot;) crs &lt;- crs(patches) patch_interiors&lt;- st_read(&quot;data/patches/highsev_patches_interior.shp&quot;) %&gt;% st_transform(crs=crs) patch_exteriors&lt;- st_read(&quot;data/patches/highsev_patches_exterior.shp&quot;) %&gt;% st_transform(crs=crs) mtbs_export &lt;- st_read(&#39;data/fire_boundaries/mtbs_export.shp&#39;) %&gt;% st_transform(crs=crs) fires_export &lt;- st_read(&quot;data/fire_boundaries/fires_export.shp&quot;)%&gt;% st_transform(crs=crs) 5.2 Create Sampling Quadrants 5.2.1 Split Patches by North/South Aspects and Interior/Exterior # create list of fire IDs fire_list &lt;- unique(patches$Evnt_ID) quadrants_df = list() for(i in fire_list){ # filter patch interiors/exteriors to the selected fire patch_fire &lt;- patches %&gt;% filter(Evnt_ID == i) mapview(patch_fire) patches_interior &lt;- patch_interiors %&gt;% filter(Evnt_ID == i)%&gt;% st_make_valid() %&gt;% st_union() patches_exterior &lt;- patch_exteriors %&gt;% filter(Evnt_ID_1 == i)%&gt;% st_make_valid()%&gt;% st_union() # set event and fire id to the selected fire Evnt_ID &lt;- i Fire_ID &lt;-names(which.max(table(patch_fire$Fire_ID))) print(paste0(&quot;starting event &quot;,Evnt_ID,&quot; in fire group &quot;, Fire_ID)) # get and calculate cosine corrected aspect dem &lt;- get_elev_raster(patch_fire,z=11) aspect &lt;- terrain(dem, opt = &quot;aspect&quot;,unit = &quot;radians&quot;) ccaspect &lt;- cos(aspect) # positive aspects are north-facing, negative are south-facing ccaspect[ccaspect&gt;0] &lt;- 1 ccaspect[ccaspect&lt;0] &lt;- -1 ccaspect_poly &lt;- as.polygons(rast(ccaspect)) %&gt;% st_as_sf() pos_aspect &lt;- ccaspect_poly %&gt;% filter(layer==1)%&gt;% st_make_valid() neg_aspect &lt;- ccaspect_poly %&gt;% filter(layer==-1) %&gt;% st_make_valid() # get quadrants as the intersection of interior/exterior and pos/neg aspect pos_ext &lt;- st_intersection(patches_exterior,pos_aspect)%&gt;% st_make_valid() %&gt;% st_union() %&gt;% st_as_sf()%&gt;% mutate(quadrant = &quot;pos_ext&quot;, Evnt_ID = i, quad_id_event = paste0(Evnt_ID,&quot;-&quot;,quadrant), Fire_ID = Fire_ID, quad_id_fire = paste0(Fire_ID,&quot;-&quot;,quadrant)) pos_int &lt;- st_intersection(patches_interior,pos_aspect)%&gt;% st_make_valid() %&gt;% st_union()%&gt;% st_as_sf()%&gt;% mutate(quadrant = &quot;pos_int&quot;, Evnt_ID = i, quad_id_event = paste0(Evnt_ID,&quot;-&quot;,quadrant), Fire_ID = Fire_ID, quad_id_fire = paste0(Fire_ID,&quot;-&quot;,quadrant)) neg_ext &lt;- st_intersection(patches_exterior,neg_aspect)%&gt;% st_make_valid() %&gt;% st_union() %&gt;% st_as_sf()%&gt;% mutate(quadrant = &quot;neg_ext&quot;, Evnt_ID = i, quad_id_event = paste0(Evnt_ID,&quot;-&quot;,quadrant), Fire_ID = Fire_ID, quad_id_fire = paste0(Fire_ID,&quot;-&quot;,quadrant)) neg_int &lt;- st_intersection(patches_interior, neg_aspect)%&gt;% st_make_valid() %&gt;% st_union() %&gt;% st_as_sf()%&gt;% mutate(quadrant = &quot;neg_int&quot;, Evnt_ID = i, quad_id_event = paste0(Evnt_ID,&quot;-&quot;,quadrant), Fire_ID = Fire_ID, quad_id_fire = paste0(Fire_ID,&quot;-&quot;,quadrant)) # combine, export quadrants all_quadrants &lt;- rbind(neg_int,pos_int,neg_ext,pos_ext) %&gt;% st_transform(crs=crs) quadrants_df[[i]] &lt;- all_quadrants print(paste0(&quot;completed&quot;)) } # bind list together quadrants_fullset &lt;- do.call(rbind,quadrants_df) %&gt;% st_as_sf() 5.2.2 Clean Quadrants # removes erroneous polygons created from irregular fire boundary shapes # removes small border mismatched fire quadrants_clean &lt;- quadrants_fullset %&gt;% mutate(area=as.numeric(st_area(x))) %&gt;% filter(area &gt; 1) %&gt;% group_by(Evnt_ID) %&gt;% mutate(n=n()) %&gt;% filter(n == 4) # clean up for export quadrants_export &lt;- quadrants_clean %&gt;% st_make_valid() %&gt;% st_as_sf() %&gt;% dplyr::select(-&quot;area&quot;)%&gt;% st_transform(crs=crs) 5.3 Export Data # st_write(quadrants_export,&quot;data/patches/&quot;,&quot;quadrants_export.shp&quot;,driver = &quot;ESRI Shapefile&quot;) "],["model-training-points.html", "Part 6 Model Training Points 6.1 Set Up 6.2 Import Data 6.3 Sampling Points 6.4 Export Data", " Part 6 Model Training Points 6.1 Set Up 6.1.0.1 Libraries library(tidyverse) library(sf) library(terra) 6.1.1 Fire List fire_list &lt;- c(&quot;Fire_1_1988&quot;,&quot;Fire_2_1988&quot;,&quot;Fire_3_1988&quot;,&quot;Fire_4_1988&quot;,&quot;Fire_7_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_31_1988&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_35_1989&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_42_1989&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_51_1991&quot;,&quot;Fire_54_1991&quot;) 6.2 Import Data patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% st_transform(crs=&quot;EPSG: 4326&quot;) crs &lt;- crs(patches) quadrants &lt;- st_read(&quot;data/patches/quadrants_export.shp&quot;) %&gt;% st_transform(crs=crs) 6.3 Sampling Points 6.3.1 Import and Combine Training Points # list and combine training data points points_list &lt;- list.files(path = &quot;data/points/individual_fire_points/&quot;, pattern=&#39;.shp&#39;, all.files=TRUE, full.names=TRUE) points_all &lt;- lapply(points_list, st_read) points &lt;- do.call(rbind,points_all) %&gt;% st_transform(crs=crs) 6.3.2 Assign Points and Clean Data # join points dataset back to fires to fill out dataset points_joined &lt;- st_join(points,patches,left=TRUE,largest=TRUE) %&gt;% st_join(.,quadrants,left=TRUE,largest=TRUE) points_cleaned &lt;- points_joined %&gt;% dplyr::select(&quot;class&quot;,&quot;ptch_r_&quot;,&quot;Evnt_ID.x&quot;,&quot;Incd_Nm&quot;,&quot;Fire_ID.x&quot;,&quot;year&quot;,&quot;ecoregn&quot;,&quot;ptch_fr&quot;,&quot;quadrnt&quot;,&quot;qd_d_vn&quot;,&quot;qd_d_fr&quot;) %&gt;% rename(patch_area_ha = ptch_r_, Event_ID = Evnt_ID.x, Incid_Name = Incd_Nm, Fire_ID = Fire_ID.x, patch_frtype = ptch_fr, quad = quadrnt, quad_event_id= qd_d_vn, quad_fire_id=qd_d_fr) %&gt;% filter(Fire_ID %in% fire_list) %&gt;% st_transform(crs=crs) 6.4 Export Data # st_write(points_cleaned, &quot;data/points/&quot;, &quot;points_export.shp&quot;,driver = &#39;ESRI Shapefile&#39;) "],["snow-cover-imagery.html", "Part 7 Snow-Cover Imagery 7.1 Set Up 7.2 Create Snow-Cover Landsat Collection 7.3 Create Annual Image Composites 7.4 Prepare and Export Images", " Part 7 Snow-Cover Imagery 7.1 Set Up 7.1.1 Import Fire Boundaries // import fire polygons var fires_export = ee.FeatureCollection(&quot;projects/westernconiferregen/assets/fires_export&quot;); var fires_export_buffer1500 = ee.FeatureCollection(&quot;projects/westernconiferregen/assets/fires_export_buffer1500&quot;); 7.1.2 Import Landsat Imagery // import Landsat 4,5,7, rename bands var ls7 = ee.ImageCollection(&#39;LANDSAT/LE07/C01/T1_SR&#39;), ls5 = ee.ImageCollection(&#39;LANDSAT/LT05/C01/T1_SR&#39;), ls4 = ee.ImageCollection(&#39;LANDSAT/LT04/C01/T1_SR&#39;); var ls4_7 = ee.ImageCollection(ls7.merge(ls5).merge(ls4)).map(function(image) { var bands = [&#39;B1&#39;,&#39;B2&#39;, &#39;B3&#39;, &#39;B4&#39;, &#39;B5&#39;, &#39;B7&#39;, &#39;pixel_qa&#39;]; var new_bands = [&#39;blue&#39;, &#39;green&#39;, &#39;red&#39;, &#39;nir&#39;, &#39;swir1&#39;, &#39;swir2&#39;, &#39;pixel_qa&#39;]; return image.select(bands).rename(new_bands); }); // import Landsat 8, rename bands var ls8 = ee.ImageCollection(&#39;LANDSAT/LC08/C01/T1_SR&#39;).map(function(image) { var bands = [&#39;B2&#39;, &#39;B3&#39;, &#39;B4&#39;, &#39;B5&#39;, &#39;B6&#39;, &#39;B7&#39;, &#39;pixel_qa&#39;]; var new_bands = [&#39;blue&#39;, &#39;green&#39;, &#39;red&#39;, &#39;nir&#39;, &#39;swir1&#39;, &#39;swir2&#39;, &#39;pixel_qa&#39;]; return image.select(bands).rename(new_bands); }); // merge Landsat 4-7 and 8 with renamed bands var ls4_8 = ee.ImageCollection(ls8.merge(ls4_7)); 7.2 Create Snow-Cover Landsat Collection 7.2.1 Functions to Prepare Images 7.2.1.1 Get Spectral Indices // function: get spectral indices var calc_indices = function(image) { return image .addBands(image.normalizedDifference([&#39;nir&#39;, &#39;red&#39;]).double().rename(&#39;ndvi&#39;)) .addBands(image.normalizedDifference([&#39;green&#39;, &#39;nir&#39;]).double().rename(&#39;ndwi&#39;)) .addBands(image.normalizedDifference([&#39;nir&#39;, &#39;swir2&#39;]).double().rename(&#39;nbr&#39;)) .addBands(image.normalizedDifference([&#39;swir1&#39;,&#39;swir2&#39;]).double().rename(&#39;nbr2&#39;)) .addBands(image.normalizedDifference([&#39;green&#39;, &#39;swir1&#39;]).double().rename(&#39;ndsi&#39;)) .addBands(image.normalizedDifference([&#39;nir&#39;,&#39;swir1&#39;]).double().rename(&#39;ndfsi&#39;)) .addBands(image.expression(&#39;2.5 * ((NIR - R) / (NIR + 6 * R - 7.5 * B + 1))&#39; ,{&#39;NIR&#39;:image.select(&#39;nir&#39;),&#39;R&#39;:image.select(&#39;red&#39;),&#39;B&#39;:image.select(&#39;blue&#39;)}).rename(&#39;evi&#39;))}; 7.2.1.2 Get Clear Images // function: pixel QA for clouds and bodies of water var qa_mask = function(lsImg){ var quality =lsImg.select([&#39;pixel_qa&#39;]); var clear = quality.bitwiseAnd(8).eq(0) // cloud shadow .and(quality.bitwiseAnd(32).eq(0) // cloud .and(quality.bitwiseAnd(4).eq(0))); // water return lsImg.updateMask(clear) .copyProperties(lsImg, [&#39;system:time_start&#39;]); }; 7.2.1.3 Get snow-Covered Pixels // function: mask pixels without snow based on NDSI and NDFSI var ndfsi_mask = function(image){ var ndfsi_snow = image.select(&#39;ndfsi&#39;).gt(0.4); return image.updateMask(ndfsi_snow); }; var ndsi_mask = function(image){ var ndsi_snow = image.select(&#39;ndsi&#39;).gt(0.4); return image.updateMask(ndsi_snow); }; 7.2.2 Map Functions Across Image Collection // map functions to create final Landsat collection var ls_indices = ls4_8.map(calc_indices) .map(qa_mask) .map(ndfsi_mask) .map(ndsi_mask); 7.3 Create Annual Image Composites 7.3.1 Functions to Create Annual Image Composites 7.3.1.1 Get Yearly Winter Image Composite // function: generates landsat composites for a given year&#39;s winter var get_composites = function(year) { // format years var year_start = ee.Number(year).format().slice(0,4); var year2 = ee.Number(year).add(1) var year_end = ee.Number(year2).format().slice(0,4); var month_start = &#39;-11-01&#39;; var month_end = &#39;-05-01&#39; var start_date = ee.String(year_start).cat(month_start) var end_date = ee.String(year_end).cat(month_end) // filter images by bounds, date range, bands; then take composite as median return ls_indices .filterBounds(fires_export_buffer1500) .filterDate(start_date,end_date) .filter(ee.Filter.calendarRange(12,4,&quot;month&quot;)) .select(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;nir&quot;, &quot;swir1&quot;, &quot;swir2&quot;, &quot;ndvi&quot;, &quot;ndwi&quot;, &quot;nbr&quot;, &quot;nbr2&quot;, &quot;ndsi&quot;, &quot;ndfsi&quot;, &quot;evi&quot;) .median() .set(&quot;year_start&quot;,year_start) .set(&quot;year_end&quot;,year_end) } 7.3.1.2 Get the Annual Imagery for Each Fire // function: clip each image from image collection by each feature in feature collection var clip_collections = function(imagecol, featcol){ // image collection loop var full_imagecol = imagecol.map(function(image){ // feature collection loop var full_featcol = featcol.map(function(feat){ // clip image and add feature property id return ee.Image(image).clip(ee.Feature(feat)) .set({&#39;feat&#39;: ee.Feature(feat).id()}) .set(&quot;Fire_ID&quot;,feat.get(&quot;Fire_ID&quot;)); }); // convert the FeatureCollection to list and convert it to ImageCollection return ee.ImageCollection.fromImages(full_featcol.toList(featcol.size())); }); // flatten, unnest lists return ee.ImageCollection(full_imagecol.flatten()); }; 7.3.2 Apply Functions to Each Image // list of start years var yearlist = ee.List.sequence(1984,2020,1); // map over the list of years to return landsat image composites for each var wrap_img = yearlist.map(get_composites); // clip landsat composites to each fire boundary var landsat_col = ee.ImageCollection.fromImages(wrap_img) // clip output var output = clip_collections(landsat_col, fires_export_buffer1500) 7.4 Prepare and Export Images // list fire IDs and get total number of fires var fireID = ee.List(fires_export_buffer1500.aggregate_array(&#39;Fire_ID&#39;)).getInfo(); var nFires = fireID.length; 7.4.1 Functions to Prepare Images 7.4.1.1 Get Year-Wavelength Band Names // rename bands to include imagery year var name_bands = function(image) { var div = ee.String(&#39;_&#39;); var year = image.getString(&#39;year_start&#39;); return image.rename(image.bandNames().map(function(bandName){ return ee.String(bandName).cat(div).cat(year); })); }; 7.4.1.2 Get Cleaned Band Name Strings // remove prefix from toBands function var clean_band_names = function(bandName){ return ee.String(bandName).slice(24,50) } 7.4.2 Export // loop through all fires, and create single image with bands from each landsat composite year // export to drive for (var j = 0; j &lt; nFires; j++){ var id = fireID[j]; var fireExport = output.filterMetadata(&#39;Fire_ID&#39;, &#39;equals&#39;, id) var firePolygon = ee.Feature(fires_export_buffer1500.filterMetadata(&#39;Fire_ID&#39;, &#39;equals&#39;, id).first()).geometry(); var fireExport_bands = fireExport.map(name_bands) var merge = fireExport_bands.toBands() var exportImg= merge.rename(merge.bandNames().map(clean_band_names)); Export.image.toDrive({ image: exportImg, folder: &quot;landsat_clipped_13bandyearly&quot;, description: id, crs: &quot;EPSG:4326&quot;, maxPixels: 1e13, scale: 30, region: firePolygon }); } "],["random-forest-model-development.html", "Part 8 Random Forest Model Development 8.1 Set Up 8.2 Prepare Imagery 8.3 Extract Landsat Data 8.4 Examine Data 8.5 Model", " Part 8 Random Forest Model Development 8.1 Set Up 8.1.1 Libraries library(mapview) library(sf) library(terra) library(tidyverse) library(ggplot2) library(car) library(forcats) library(randomForest) library(raster) 8.1.2 Import Fire Boundaries fires_export &lt;- st_read(&quot;data/fire_boundaries/fires_export.shp&quot;)%&gt;% st_transform(., crs=&quot;EPSG: 4326&quot;) ## Reading layer `fires_export&#39; from data source ## `C:\\Users\\Casey\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\fire_boundaries\\fires_export.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 54 features and 20 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -118.6259 ymin: 42.57259 xmax: -106.9485 ymax: 48.9346 ## Geodetic CRS: WGS 84 crs &lt;- crs(fires_export) 8.1.3 Import Training Points # bring in training points points &lt;- st_read(&quot;data/points/points_export.shp&quot;) %&gt;% st_transform(crs=crs)%&gt;% drop_na() ## Reading layer `points_export&#39; from data source ## `C:\\Users\\Casey\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\points\\points_export.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 4472 features and 11 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -118.6075 ymin: 42.57725 xmax: -106.9652 ymax: 48.83974 ## Geodetic CRS: WGS 84 8.2 Prepare Imagery 8.2.1 Prepare Data for Bands and Fire Names 8.2.1.1 Bands # list band names and years bands &lt;- c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;nir&quot;, &quot;swir1&quot;, &quot;swir2&quot;, &quot;ndvi&quot;, &quot;ndwi&quot;, &quot;nbr&quot;, &quot;nbr2&quot;, &quot;ndsi&quot;, &quot;ndfsi&quot;, &quot;evi&quot;) years &lt;- c(1984:2020) # create list of all combinations of bands, in the appropriate order bandlist &lt;- outer(bands, years, paste, sep=&quot;&quot;) 8.2.1.2 Fire Names # get list of fire names fire_names_all &lt;- unique(fires_export$Fire_ID) fire_names_points &lt;- unique(points$Fire_ID,na.rm=TRUE) 8.2.2 Merge Large Rasters # function to merge rasters, if there are multiple in the folder export_rasters &lt;- function(fire_name){ print(paste0(&quot;Starting Fire &quot;,fire_name)) # get list of this fire&#39;s tif files rast_list &lt;- list.files(path = &quot;data/landsat/landsat_annual&quot;, pattern=fire_name, all.files=TRUE, full.names=TRUE) # larger rasters were exported from GEE as multiple files, need to be combined before importing if (length(rast_list)&gt;1) { print(paste0(length(rast_list),&quot; rasters, merging...&quot;)) rast_all &lt;- lapply(rast_list, rast) rast_collection &lt;- do.call(merge,rast_all) writeRaster(rast_collection, str_c(&quot;data/landsat/landsat_annual/&quot;,fire_name,&quot;.tif&quot;), overwrite=FALSE,gdal=&quot;COMPRESS=NONE&quot;) } else { print(&quot;Only one raster, can extract directly&quot;) } } # map across all fire events, merging rasters where there are multiple map(fire_names_all,export_rasters) 8.3 Extract Landsat Data # function to extract the snow-cover landsat values for the training data points extract_landsat &lt;- function(fire_name){ print(paste0(&quot;Starting Fire &quot;,fire_name)) # get this fire&#39;s tif files rast_list &lt;- list.files(path = &quot;data/landsat/landsat_training&quot;, pattern=str_c(fire_name,&quot;.tif&quot;), all.files=TRUE, full.names=TRUE) rast_fire &lt;- rast(rast_list) # name the bands names(rast_fire) &lt;- bands # verify crs crs(rast_fire) &lt;- &quot;EPSG: 4326&quot; # filter the points for this fire fire_points &lt;- points %&gt;% filter(Fire_ID==fire_name) %&gt;% st_transform(crs=crs(rast_fire)) # get the mean landsat values for each patch in this fire extracted_points &lt;- st_as_sf(terra::extract(rast_fire, fire_points,bind = TRUE)) # export return(extracted_points) } # extract landsat values to each training point extracted_df &lt;- map(fire_names_points, extract_landsat) 8.3.1 Prepare Dataset # compile dataset and clean dataset training_dataset &lt;- do.call(rbind,extracted_df) %&gt;% mutate(absence = as.factor(case_when(class == &quot;absence&quot; ~ &quot;absence&quot;, TRUE ~ &quot;presence&quot;)), binom = as.factor(case_when(class == &quot;absence&quot; ~ 0, TRUE ~ 1)), class = case_when(class == &quot;presence20to40&quot; ~ &quot;20-60%&quot;, class == &quot;presence40to60&quot; ~ &quot;20-60%&quot;, class == &quot;presence10to20&quot; ~ &quot;10-20%&quot;, class == &quot;presence1to10&quot; ~ &quot;1-10%&quot;, class == &quot;presencetrace&quot; ~ &quot;&lt;1%&quot;, class == &quot;presence60plus&quot; ~ &quot;&gt;60%&quot;, TRUE ~ &quot;absence&quot;), class = fct_relevel(as.factor(class),c(&quot;absence&quot;,&quot;&lt;1%&quot;,&quot;1-10%&quot;,&quot;10-20%&quot;,&quot;20-60%&quot;,&quot;&gt;60%&quot;))) %&gt;% st_drop_geometry() %&gt;% dplyr::select(-qd_vnt_,-qd_fr_d) %&gt;% drop_na(ndvi) 8.4 Examine Data 8.4.1 Plot NDVI by Density Class # plot the NDVI of the training data points by visually estimated conifer cover ggplot(training_dataset,aes(class,ndvi)) + geom_boxplot() + labs(title = &quot;Training Data NDVI by Percent Conifer Cover Class&quot;,x = &quot;Visually Estimated Conifer Percent Cover&quot;,y = &quot;NDVI&quot;) + theme_classic() ggplot(training_dataset %&gt;% filter(class %in% c(&quot;absence&quot;,&quot;&lt;1%&quot;)),aes(class,ndvi)) + geom_boxplot()+ ylim(-.1,.1) + labs(title = &quot;Training Data NDVI by Percent Conifer Cover Class&quot;, subtitle = &quot;Comparing Trace Conifer Cover Class vs. Absence&quot;,x = &quot;Visually Estimated Conifer Percent Cover&quot;,y = &quot;NDVI&quot;) + theme_classic() ggplot(training_dataset,aes(absence,ndvi)) + geom_boxplot() + labs(title = &quot;Training Data NDVI by Percent Conifer Cover Class &quot;, subtitle = &quot;Comparing Conifer Presence vs. Absence&quot;,x = &quot;Conifer Status&quot;,y = &quot;NDVI&quot;)+ theme_classic() 8.5 Model 8.5.1 Create Random Forest Model # create RF model of conifer presence-absence based on snow-cover landsat image bands rf_conifer &lt;- randomForest(binom ~ red + green + blue + nir + swir1 + swir2 + ndsi + ndfsi + ndvi + evi + nbr + nbr2 + ndwi, data = training_dataset %&gt;% drop_na()) 8.5.2 Evaluate Parameters # model object rf_conifer ## ## Call: ## randomForest(formula = binom ~ red + green + blue + nir + swir1 + swir2 + ndsi + ndfsi + ndvi + evi + nbr + nbr2 + ndwi, data = training_dataset %&gt;% drop_na()) ## Type of random forest: classification ## Number of trees: 500 ## No. of variables tried at each split: 3 ## ## OOB estimate of error rate: 11.74% ## Confusion matrix: ## 0 1 class.error ## 0 718 255 0.26207605 ## 1 267 3208 0.07683453 # variable importance randomForest::importance(rf_conifer) ## MeanDecreaseGini ## red 68.28987 ## green 79.67736 ## blue 94.10640 ## nir 60.70280 ## swir1 73.89455 ## swir2 98.20424 ## ndsi 78.78686 ## ndfsi 87.30605 ## ndvi 314.43385 ## evi 77.90325 ## nbr 119.79740 ## nbr2 130.02165 ## ndwi 238.41816 # confusion matrix rf_conifer$confusion ## 0 1 class.error ## 0 718 255 0.26207605 ## 1 267 3208 0.07683453 # summary summary(rf_conifer) ## Length Class Mode ## call 3 -none- call ## type 1 -none- character ## predicted 4448 factor numeric ## err.rate 1500 -none- numeric ## confusion 6 -none- numeric ## votes 8896 matrix numeric ## oob.times 4448 -none- numeric ## classes 2 -none- character ## importance 13 -none- numeric ## importanceSD 0 -none- NULL ## localImportance 0 -none- NULL ## proximity 0 -none- NULL ## ntree 1 -none- numeric ## mtry 1 -none- numeric ## forest 14 -none- list ## y 4448 factor numeric ## test 0 -none- NULL ## inbag 0 -none- NULL ## terms 3 terms call 8.5.3 Export Model Object # export # saveRDS(rf_conifer,&quot;data/models/rf_conifer.rds&quot;) "],["conifer-presence-absence-prediction.html", "Part 9 Conifer Presence-Absence Prediction 9.1 Set Up 9.2 Presence-Absence Rasters", " Part 9 Conifer Presence-Absence Prediction 9.1 Set Up 9.1.1 Libraries library(sf) library(terra) library(tidyverse) library(ggplot2) library(randomForest) library(raster) library(mapview) 9.1.2 Import Fire Boundaries # import high-severity patches patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% st_transform(crs=&quot;EPSG: 4326&quot;) # set crs crs &lt;- crs(patches) # import fire boundaries fires_export &lt;- st_read(&quot;data/fire_boundaries/fires_export.shp&quot;)%&gt;% st_transform(., crs=crs) # import mask of plantings and fires mask &lt;- st_read(&quot;data/patches/points_dataset_MASK.shp&quot;) %&gt;% st_transform(crs=crs) %&gt;% st_join(.,fires_export) 9.1.3 Import Model rf_conifer &lt;- readRDS(&quot;data/models/rf_conifer.rds&quot;) 9.1.4 Prepare Raster Naming 9.1.4.1 Bands # list band names and years bands &lt;- c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;nir&quot;, &quot;swir1&quot;, &quot;swir2&quot;, &quot;ndvi&quot;, &quot;ndwi&quot;, &quot;nbr&quot;, &quot;nbr2&quot;, &quot;ndsi&quot;, &quot;ndfsi&quot;, &quot;evi&quot;) years &lt;- c(1984:2020) # create list of all combinations of bands, in the appropriate order bandlist &lt;- outer(bands, years, paste, sep=&quot;&quot;) 9.1.4.2 Fire Names # get list of fire names fire_names &lt;- c(&quot;Fire_1_1988&quot;,&quot;Fire_2_1988&quot;,&quot;Fire_3_1988&quot;,&quot;Fire_4_1988&quot;,&quot;Fire_7_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_31_1988&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_35_1989&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_42_1989&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_51_1991&quot;,&quot;Fire_54_1991&quot;) 9.2 Presence-Absence Rasters 9.2.1 Predict Presence Across 3-Year Intervals # function to apply the RF model to predict conifer presence-absence at 3-year intervals predict_landsat &lt;- function(fire_name){ print(paste0(&quot;Starting Fire &quot;,fire_name)) # import fire raster rast_list &lt;- list.files(path = &quot;data/landsat/landsat_annual&quot;, pattern=str_c(fire_name,&quot;.tif&quot;), all.files=TRUE, full.names=TRUE) fire_raster &lt;- rast(rast_list) # name the bands, verify crs names(fire_raster) &lt;- bandlist crs(fire_raster) &lt;- &quot;EPSG: 4326&quot; # filter the patches for this fire fire_patches &lt;- patches %&gt;% filter(Fire_ID==fire_name) %&gt;% st_transform(crs=crs(fire_raster)) # filter mask for this fire fire_mask &lt;- mask %&gt;% filter(Fire_ID == fire_name) # clip raster to outside of any masked areas fire_raster_mask &lt;- mask(fire_raster,fire_mask,inverse=TRUE) # clip raster to patches raster_clip &lt;- mask(fire_raster_mask,fire_patches) # set fire year fire_year_start &lt;- mean(fire_patches$year) fire_year_end &lt;- fire_year_start + 30 # string of start years for 3-year image composites fire_year_seq &lt;- sequence(10,from=fire_year_start, by = 3) pred_rasters &lt;- list() for(i in 1:10){ print(i) raster_yr1 &lt;- raster_clip[as.character(fire_year_seq[i])] raster_yr2 &lt;- raster_clip[as.character(fire_year_seq[i]+1)] raster_yr3 &lt;- raster_clip[as.character(fire_year_seq[i]+2)] names(raster_yr1) &lt;- list(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;nir&quot;, &quot;swir1&quot;, &quot;swir2&quot;, &quot;ndvi&quot;, &quot;ndwi&quot;, &quot;nbr&quot;, &quot;nbr2&quot;, &quot;ndsi&quot;, &quot;ndfsi&quot;, &quot;evi&quot;) names(raster_yr2) &lt;- list(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;nir&quot;, &quot;swir1&quot;, &quot;swir2&quot;, &quot;ndvi&quot;, &quot;ndwi&quot;, &quot;nbr&quot;, &quot;nbr2&quot;, &quot;ndsi&quot;, &quot;ndfsi&quot;, &quot;evi&quot;) names(raster_yr3) &lt;- list(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;nir&quot;, &quot;swir1&quot;, &quot;swir2&quot;, &quot;ndvi&quot;, &quot;ndwi&quot;, &quot;nbr&quot;, &quot;nbr2&quot;, &quot;ndsi&quot;, &quot;ndfsi&quot;, &quot;evi&quot;) raster_set &lt;- mean(raster_yr1,raster_yr2,raster_yr3,na.rm=TRUE) # rast_predicted_lm &lt;- terra::predict(raster_set,lm_conifer, type=&quot;response&quot;, se.fit=TRUE, na.rm = TRUE,filename = str_c(&quot;data/prediction_rasters/&quot;,fire_name,&quot;_lm_year&quot;,1+((i-1)*3),&quot;to&quot;,i*3,&quot;.tif&quot;)) rast_predicted_rf &lt;- terra::predict(raster_set,rf_conifer, type=&quot;response&quot;, se.fit=TRUE, na.rm = TRUE,filename = str_c(&quot;data/prediction_rasters/&quot;,fire_name,&quot;_rf_year&quot;,1+((i-1)*3),&quot;to&quot;,i*3,&quot;.tif&quot;)) # pred_rasters[str_c(&quot;lm_year&quot;,1+((i-1)*3),&quot;to&quot;,i*3)] &lt;- rast_predicted_lm pred_rasters[str_c(&quot;rf_year&quot;,1+((i-1)*3),&quot;to&quot;,i*3)] &lt;- rast_predicted_rf } # export return(pred_rasters) } # create dataset of prediction rasters for each model in 3 year increments prediction_dataset &lt;- map(fire_names,predict_landsat) names(prediction_dataset) &lt;- fire_names "],["model-validation.html", "Part 10 Model Validation 10.1 Set Up 10.2 Create Validation Polygons 10.3 Independent Validation 10.4 Percent Cover of Misclassifications", " Part 10 Model Validation 10.1 Set Up 10.1.1 Libraries library(sf) library(terra) library(raster) library(tidyverse) library(mapview) library(caret) library(rempsyc) 10.1.2 Import Patch and Fire Boundaries # final fire list fire_names &lt;- c(&quot;Fire_1_1988&quot;,&quot;Fire_2_1988&quot;,&quot;Fire_3_1988&quot;,&quot;Fire_4_1988&quot;,&quot;Fire_7_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_31_1988&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_35_1989&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_42_1989&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_51_1991&quot;,&quot;Fire_54_1991&quot;) # import fire and patch boundaries mtbs_fires &lt;- st_read(&quot;data/fire_boundaries/mtbs_export.shp&quot;) %&gt;% filter(Fire_ID %in% fire_names)%&gt;% st_transform(crs=&quot;EPSG:4326&quot;) ## Reading layer `mtbs_export&#39; from data source ## `C:\\Users\\Casey\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\fire_boundaries\\mtbs_export.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 69 features and 8 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -118.6259 ymin: 42.57259 xmax: -106.9485 ymax: 48.9346 ## Geodetic CRS: WGS 84 highsev_patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% filter(Fire_ID %in% fire_names)%&gt;% st_transform(crs=&quot;EPSG:4326&quot;) ## Reading layer `highsev_patches&#39; from data source ## `C:\\Users\\Casey\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\patches\\highsev_patches.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 5904 features and 10 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -118.6156 ymin: 42.57637 xmax: -106.96 ymax: 48.92836 ## Geodetic CRS: WGS 84 10.1.3 Import Prediction Rasters # get all presence-absence rasters from final timepoint rast_list &lt;- list.files(path = &quot;data/prediction_rasters&quot;, pattern=&quot;t9.tif&quot;, all.files=TRUE, full.names=TRUE) 10.2 Create Validation Polygons 10.2.1 Calculate Areal Proportions for Each MTBS Event # create and map function to determine areal proportion of presence/absence for each mtbs event get_percentages &lt;- function(mtbs_event){ # filter to mtbs event mtbs_fire &lt;- mtbs_fires %&gt;% filter(Event_ID == mtbs_event) fire_name &lt;- mtbs_fire$Fire_ID # import and mask final timepoint prediction raster to the MTBS event fire_rast &lt;- list.files(path = &quot;data/prediction_rasters&quot;, pattern=str_c(fire_name,&quot;_rf_t9&quot;), all.files=TRUE, full.names=TRUE) %&gt;% rast() %&gt;% mask(.,mtbs_fire) # calculate the proportion of each class and assign the appropriate number of validation points perc &lt;- freq(fire_rast) %&gt;% mutate(Fire_ID = fire_name, MTBS_ID = mtbs_event, class = case_when(value == 1 ~ &quot;absence&quot;, value == 2 ~ &quot;presence&quot;), percent_area = round(count/sum(count),3), val_points = round(5+10*percent_area,0)) return(perc) } # combine valid_points_df &lt;- do.call(rbind,map(mtbs_fires$Event_ID,get_percentages)) 10.2.2 Create Validation Polygons for Each MTBS Event # create and map function to create presence/absence polygons from prediction raster get_polygons &lt;- function(mtbs_event){ mtbs_fire &lt;- mtbs_fires %&gt;% filter(Event_ID == mtbs_event) fire_name &lt;- mtbs_fire$Fire_ID fire_rast &lt;- list.files(path = &quot;data/prediction_rasters&quot;, pattern=str_c(fire_name,&quot;_rf_t9&quot;), all.files=TRUE, full.names=TRUE) %&gt;% rast() %&gt;% mask(.,mtbs_fire) fire_poly &lt;- as.polygons(fire_rast) fire_poly_sf &lt;- st_as_sf(fire_poly) %&gt;% mutate(Fire_ID = fire_name, MTBS_ID = mtbs_event) return(fire_poly_sf) } # combine and reformat class_polys &lt;- do.call(rbind,map(mtbs_fires$Event_ID,get_polygons)) class_polys$value &lt;- (class_polys$lyr1) valid_points_df$class &lt;- as.integer(valid_points_df$class) # add the required number of validation points to each class polygon sample_polys &lt;- left_join(class_polys,valid_points_df,by=c(&quot;Fire_ID&quot;,&quot;value&quot;,&quot;MTBS_ID&quot;)) %&gt;% st_transform(., crs=&quot;EPSG:4326&quot;) %&gt;% st_drop_geometry() 10.2.3 Export # export polygons to have validation points generated in ArcGIS Pro # st_write(sample_polys,&quot;data/validation/validation_polygons.shp&quot;) 10.3 Independent Validation validation_dataset &lt;- read_csv(&quot;data/validation/pixel_counting_val_dataset.csv&quot;) 10.3.1 Confusion Matrix by Proportion of Points # create validation matrix based on independent validation validation_matrix &lt;- validation_dataset %&gt;% group_by(classified_as, is_actually) %&gt;% summarize(n=n()) %&gt;% spread(.,key = is_actually,value = n) %&gt;% ungroup() %&gt;% dplyr::select(-classified_as)%&gt;% as.matrix() # reformat rownames(validation_matrix) &lt;- c(&quot;absence&quot;,&quot;presence&quot;) # create confusion matrix from presence-absence matrix confusion &lt;- confusionMatrix(validation_matrix,positive=&quot;presence&quot;) confusion ## Confusion Matrix and Statistics ## ## absence presence ## absence 214 149 ## presence 7 561 ## ## Accuracy : 0.8324 ## 95% CI : (0.8069, 0.8559) ## No Information Rate : 0.7626 ## P-Value [Acc &gt; NIR] : 1.255e-07 ## ## Kappa : 0.621 ## ## Mcnemar&#39;s Test P-Value : &lt; 2.2e-16 ## ## Sensitivity : 0.7901 ## Specificity : 0.9683 ## Pos Pred Value : 0.9877 ## Neg Pred Value : 0.5895 ## Prevalence : 0.7626 ## Detection Rate : 0.6026 ## Detection Prevalence : 0.6101 ## Balanced Accuracy : 0.8792 ## ## &#39;Positive&#39; Class : presence ## 10.3.2 Confusion Matrix by Areal Proportion # for each class, multiple proportion of total area by the proportion of validation points presence_presence &lt;- 0.6577376 * 561/(561+7) presence_absence &lt;- 0.6577376 * 7/(561+7) absence_absence &lt;- 0.3422624 * 214/(214+149) absence_presence &lt;- 0.3422624 * 149/(214+149) # assign rown and column names for matrix colnames &lt;- c(&quot;presence&quot;,&quot;absence&quot;) rownames&lt;- c(&quot;presence&quot;,&quot;absence&quot;) # create matrix of these areal validation proportions validation_matrix &lt;- matrix(data = c(presence_presence,absence_presence,presence_absence,absence_absence),nrow =2,dimnames = list(rownames,colnames)) # create and format data of areal validation proportions validation_df &lt;- validation_matrix %&gt;% as.data.frame() %&gt;% mutate(`Map Classification` = c(&quot;presence&quot;,&quot;absence&quot;))%&gt;% group_by(`Map Classification`) %&gt;% mutate(`Reference.Total (Wi)` = sum(presence+absence)) %&gt;% ungroup() %&gt;% mutate(Reference.Ui = c(0.6496317/0.6577376,0.201774528/0.3422624))%&gt;% rename(`Reference.Conifer Presence` = presence, `Reference.Conifer Absence` = absence)%&gt;% dplyr::select(`Map Classification`,`Reference.Conifer Presence`,`Reference.Conifer Absence`,`Reference.Total (Wi)`,Reference.Ui) # function to format table to correct digits fun &lt;- function(x) {formatC(x, format = &quot;f&quot;, digits = 3)} # format validation matrix into table for paper validation_table &lt;- nice_table( validation_df, separate.header = TRUE, col.format.custom = 1:5,format.custom = &quot;fun&quot;,width =1) table ## function (..., exclude = if (useNA == &quot;no&quot;) c(NA, NaN), useNA = c(&quot;no&quot;, ## &quot;ifany&quot;, &quot;always&quot;), dnn = list.names(...), deparse.level = 1) ## { ## list.names &lt;- function(...) { ## l &lt;- as.list(substitute(list(...)))[-1L] ## if (length(l) == 1L &amp;&amp; is.list(..1) &amp;&amp; !is.null(nm &lt;- names(..1))) ## return(nm) ## nm &lt;- names(l) ## fixup &lt;- if (is.null(nm)) ## seq_along(l) ## else nm == &quot;&quot; ## dep &lt;- vapply(l[fixup], function(x) switch(deparse.level + ## 1, &quot;&quot;, if (is.symbol(x)) as.character(x) else &quot;&quot;, ## deparse(x, nlines = 1)[1L]), &quot;&quot;) ## if (is.null(nm)) ## dep ## else { ## nm[fixup] &lt;- dep ## nm ## } ## } ## miss.use &lt;- missing(useNA) ## miss.exc &lt;- missing(exclude) ## useNA &lt;- if (miss.use &amp;&amp; !miss.exc &amp;&amp; !match(NA, exclude, ## nomatch = 0L)) ## &quot;ifany&quot; ## else match.arg(useNA) ## doNA &lt;- useNA != &quot;no&quot; ## if (!miss.use &amp;&amp; !miss.exc &amp;&amp; doNA &amp;&amp; match(NA, exclude, ## nomatch = 0L)) ## warning(&quot;&#39;exclude&#39; containing NA and &#39;useNA&#39; != \\&quot;no\\&quot;&#39; are a bit contradicting&quot;) ## args &lt;- list(...) ## if (length(args) == 1L &amp;&amp; is.list(args[[1L]])) { ## args &lt;- args[[1L]] ## if (length(dnn) != length(args)) ## dnn &lt;- paste(dnn[1L], seq_along(args), sep = &quot;.&quot;) ## } ## if (!length(args)) ## stop(&quot;nothing to tabulate&quot;) ## bin &lt;- 0L ## lens &lt;- NULL ## dims &lt;- integer() ## pd &lt;- 1L ## dn &lt;- NULL ## for (a in args) { ## if (is.null(lens)) ## lens &lt;- length(a) ## else if (length(a) != lens) ## stop(&quot;all arguments must have the same length&quot;) ## fact.a &lt;- is.factor(a) ## if (doNA) ## aNA &lt;- anyNA(a) ## if (!fact.a) { ## a0 &lt;- a ## op &lt;- options(warn = 2) ## a &lt;- factor(a, exclude = exclude) ## options(op) ## } ## add.na &lt;- doNA ## if (add.na) { ## ifany &lt;- (useNA == &quot;ifany&quot;) ## anNAc &lt;- anyNA(a) ## add.na &lt;- if (!ifany || anNAc) { ## ll &lt;- levels(a) ## if (add.ll &lt;- !anyNA(ll)) { ## ll &lt;- c(ll, NA) ## TRUE ## } ## else if (!ifany &amp;&amp; !anNAc) ## FALSE ## else TRUE ## } ## else FALSE ## } ## if (add.na) ## a &lt;- factor(a, levels = ll, exclude = NULL) ## else ll &lt;- levels(a) ## a &lt;- as.integer(a) ## if (fact.a &amp;&amp; !miss.exc) { ## ll &lt;- ll[keep &lt;- which(match(ll, exclude, nomatch = 0L) == ## 0L)] ## a &lt;- match(a, keep) ## } ## else if (!fact.a &amp;&amp; add.na) { ## if (ifany &amp;&amp; !aNA &amp;&amp; add.ll) { ## ll &lt;- ll[!is.na(ll)] ## is.na(a) &lt;- match(a0, c(exclude, NA), nomatch = 0L) &gt; ## 0L ## } ## else { ## is.na(a) &lt;- match(a0, exclude, nomatch = 0L) &gt; ## 0L ## } ## } ## nl &lt;- length(ll) ## dims &lt;- c(dims, nl) ## if (prod(dims) &gt; .Machine$integer.max) ## stop(&quot;attempt to make a table with &gt;= 2^31 elements&quot;) ## dn &lt;- c(dn, list(ll)) ## bin &lt;- bin + pd * (a - 1L) ## pd &lt;- pd * nl ## } ## names(dn) &lt;- dnn ## bin &lt;- bin[!is.na(bin)] ## if (length(bin)) ## bin &lt;- bin + 1L ## y &lt;- array(tabulate(bin, pd), dims, dimnames = dn) ## class(y) &lt;- &quot;table&quot; ## y ## } ## &lt;bytecode: 0x00000176d68c32f0&gt; ## &lt;environment: namespace:base&gt; # export table as word document # flextable::save_as_docx(table, path = &quot;data/validation/val_matrix_report.docx&quot;) 10.4 Percent Cover of Misclassifications # filter to presence misclassified as absence misclass &lt;- validation_dataset %&gt;% filter(class_group == &quot;absence-presence&quot;) # create histogram of the proportion of pixels containing conifers for these points ggplot(misclass,aes(pixel_perc)) + geom_histogram(bins = 50) + theme_classic() + labs(y = &quot;Count&quot;,x = &quot;Percent of Pixels Containing Conifers&quot;, title = &quot;Percent Conifer Cover of Pixels Misclassified as Absent&quot;, subtitle = str_c(&quot;&quot;))+ geom_vline(xintercept = 0.10,linetype = &quot;dotted&quot;) # 10% cover percentile quantile(misclass$pixel_perc,.72) ## 72% ## 0.1009333 # median percent cover quantile(misclass$pixel_perc,.5) ## 50% ## 0.06333333 "],["ndvi-trajectory.html", "Part 11 NDVI Trajectory 11.1 Set Up 11.2 Connect Landsat and High-Severity Patches 11.3 Prepare Dataset 11.4 Modeling", " Part 11 NDVI Trajectory 11.1 Set Up 11.1.1 Libraries library(ggplot2) library(ggthemes) library(tidyverse) library(sf) library(terra) library(raster) library(exactextractr) library(forcats) library(broom) library(knitr) library(sjPlot) library(lwgeom) library(lme4) library(nlme) library(segmented) 11.1.2 Import Fires # import high-severity patches patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% st_transform(crs=&quot;EPSG: 4326&quot;) %&gt;% mutate(perim = st_cast(geometry,&quot;MULTILINESTRING&quot;) %&gt;% st_length(), perim_ratio = perim/ptch_r_) # set crs crs &lt;- crs(patches) # import fire boundaries fires_export &lt;- st_read(&quot;data/fire_boundaries/fires_export.shp&quot;)%&gt;% st_transform(., crs=crs) # import mask of plantings and fires mask &lt;- st_read(&quot;data/patches/points_dataset_MASK.shp&quot;) %&gt;% st_transform(crs=crs) %&gt;% st_join(.,fires_export) # final fire list fire_names &lt;- c(&quot;Fire_54_1991&quot;,&quot;Fire_1_1988&quot;,&quot;Fire_2_1988&quot;,&quot;Fire_3_1988&quot;,&quot;Fire_4_1988&quot;,&quot;Fire_7_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_31_1988&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_35_1989&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_42_1989&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_51_1991&quot;) 11.1.3 Prepare Data for Bands and Fire Names 11.1.3.1 Bands # list band names and years bands &lt;- c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;nir&quot;, &quot;swir1&quot;, &quot;swir2&quot;, &quot;ndvi&quot;, &quot;ndwi&quot;, &quot;nbr&quot;, &quot;nbr2&quot;, &quot;ndsi&quot;, &quot;ndfsi&quot;, &quot;evi&quot;) years &lt;- c(1984:2020) # create list of all combinations of bands, in the appropriate order bandnames &lt;- expand_grid(years,bands) %&gt;% mutate(V1 = str_c(bands,years)) bandlist &lt;- bandnames$V1 11.2 Connect Landsat and High-Severity Patches 11.2.1 Extract Landsat Data for Each Patch extract_landsat &lt;- function(fire_name){ print(paste0(&quot;Starting Fire &quot;,fire_name)) # get list of this fire&#39;s tif files rast_list &lt;- list.files(path = &quot;data/landsat/landsat_annual&quot;, pattern = str_c(fire_name,&quot;.tif&quot;), all.files=TRUE, full.names=TRUE) rast_fire &lt;- rast(rast_list) # name the bands names(rast_fire) &lt;- bandlist # verify crs crs(rast_fire) &lt;- &quot;EPSG: 4326&quot; # filter the patches for this fire fire_patches &lt;- patches %&gt;% filter(Fire_ID==fire_name) %&gt;% st_transform(crs=crs(rast_fire)) fire_mask &lt;- mask %&gt;% filter(Fire_ID == fire_name) rast_fire &lt;- mask(rast_fire,fire_mask,inverse=TRUE) # get the mean landsat values for each patch in this fire extracted_data &lt;- left_join(fire_patches, exact_extract(rast_fire,fire_patches, append_cols = TRUE, max_cells_in_memory = 3e+08, fun = &quot;mean&quot;)) %&gt;% st_drop_geometry() # export # return(extracted_data) write_csv(extracted_data,str_c(&quot;data/ndvi_trajectory/&quot;,fire_name,&quot;.csv&quot;)) } # map extraction function across all fires extracted_fires &lt;- map(fire_names,extract_landsat) # combine landsat dataset landsat_dataset&lt;- lapply(list.files(path = &quot;data/ndvi_trajectory&quot;, pattern = str_c(&quot;Fire&quot;), all.files=TRUE, full.names=TRUE),read_csv) %&gt;% do.call(rbind,.) 11.3 Prepare Dataset 11.3.1 Clean Data # clean dataset, label, select only ndvi, calculate pre-fire ndvi &amp; differenced ndvi ndvi_dataset_full &lt;- landsat_dataset %&gt;% mutate(Patch_ID = str_c(Fire_ID,&quot;-&quot;,1:n()), prefire_yr = as.integer(year-1), patch_area_class = fct_relevel(as.factor(case_when(ptch_r_ &gt;= 1000 ~ &quot;&gt;1000 acres&quot;, ptch_r_ &lt; 1000 &amp; ptch_r_ &gt;= 500 ~ &quot;500-1000 acres&quot;, ptch_r_ &lt; 500 &amp; ptch_r_ &gt;= 100 ~ &quot;100-500 acres&quot;, ptch_r_ &lt; 100 &amp; ptch_r_ &gt;= 50 ~ &quot;50-100 acres&quot;, ptch_r_ &lt; 50 &amp; ptch_r_ &gt;= 10 ~ &quot;10-50 acres&quot;, TRUE ~ &quot;&lt;10 acres&quot;)), c(&quot;&lt;10 acres&quot;,&quot;10-50 acres&quot;,&quot;50-100 acres&quot;,&quot;100-500 acres&quot;,&quot;500-1000 acres&quot;,&quot;&gt;1000 acres&quot;))) %&gt;% dplyr::select(Evnt_ID, Incd_Nm, Fire_ID, Patch_ID, prefire_yr, year, ecoregn, ptch_fr, ptch_r_, patch_area_class, contains(&quot;ndvi&quot;)) %&gt;% pivot_longer(.,contains(&quot;ndvi&quot;),names_to = &quot;landsat_yr&quot;, values_to = &quot;ndvi&quot;)%&gt;% mutate(landsat_yr = as.integer(landsat_yr %&gt;% stringr::str_remove(&quot;mean.ndvi&quot;)), years_postfire = landsat_yr - year) %&gt;% mutate(prefire_ndvi = case_when(years_postfire == -1 ~ ndvi)) %&gt;% group_by(Patch_ID) %&gt;% mutate(prefire_ndvi = mean(prefire_ndvi, na.rm=TRUE)) %&gt;% ungroup() %&gt;% mutate(delta_ndvi = ndvi - prefire_ndvi)%&gt;% filter(ptch_fr %in% c(&quot;Lodegepole Pine&quot;,&quot;Douglas-Fir&quot;,&quot;Fir-Spruce&quot;), Fire_ID %in% fire_names) %&gt;% mutate(ptch_fr = case_when(ptch_fr == &quot;Lodegepole Pine&quot; ~ &quot;Lodgepole Pine&quot;, TRUE ~ ptch_fr))%&gt;% drop_na() 11.4 Modeling 11.4.1 Forest Type Groups 11.4.1.1 Model # group ndvi values by forest type and years post-fire ndvi_grouped_type &lt;- ndvi_dataset_full %&gt;% group_by(ptch_fr,years_postfire) %&gt;% summarize(ndvi=mean(ndvi,na.rm=TRUE), delta_ndvi = mean(delta_ndvi,na.rm=TRUE)) %&gt;% drop_na() # prepare datasets for each forest type data_df &lt;- ndvi_grouped_type%&gt;% filter(ptch_fr == &quot;Douglas-Fir&quot;,years_postfire&gt;=0) data_lp &lt;- ndvi_grouped_type%&gt;% filter(ptch_fr == &quot;Lodgepole Pine&quot;,years_postfire&gt;=0) data_fs&lt;- ndvi_grouped_type%&gt;% filter(ptch_fr == &quot;Fir-Spruce&quot;,years_postfire&gt;=0) # model dNDVI for each forest type through time lm_ndvi_df &lt;- lm(delta_ndvi ~ years_postfire, data = data_df%&gt;% filter(years_postfire&gt;=0)) seg_ndvi_df &lt;- segmented(lm_ndvi_df,seg.Z = ~ years_postfire,npsi =1) data_df$fit &lt;- seg_ndvi_df$fitted.values lm_ndvi_lp &lt;- lm(delta_ndvi ~ years_postfire, data = data_lp) seg_ndvi_lp &lt;- segmented(lm_ndvi_lp,seg.Z = ~ years_postfire,npsi =1) data_lp$fit &lt;- seg_ndvi_lp$fitted.values lm_ndvi_fs &lt;- lm(delta_ndvi ~ years_postfire, data = data_fs ) seg_ndvi_fs &lt;- segmented(lm_ndvi_fs,seg.Z = ~ years_postfire,npsi =1) data_fs$fit &lt;- seg_ndvi_fs$fitted.values 11.4.1.2 Estimates estimate_yrs_recovery &lt;- function(model){ bp &lt;- as.numeric(model$indexU) slopes &lt;- slope(model) %&gt;% as.data.frame() slope1 &lt;- slopes$years_postfire.Est.[1] slope2 &lt;- slopes$years_postfire.Est.[2] intercept &lt;- model$coefficients[1] new_intercept &lt;- intercept + slope1 * bp est_rec &lt;- -new_intercept/slope2 + bp r2 &lt;- summary(model)$adj.r.squared df &lt;- data.frame(forest_type = NA, intercept = intercept, slope_pre = slope1, slope_post = slope2, years_detect = bp, years_recover = est_rec, adj_R2 = r2) return(df) } seg_models &lt;- rbind(estimate_yrs_recovery(seg_ndvi_df), estimate_yrs_recovery(seg_ndvi_lp), estimate_yrs_recovery(seg_ndvi_fs)) %&gt;% mutate(forest_type = c(&quot;Douglas-Fir&quot;,&quot;Lodgepole Pine&quot;,&quot;Fir-Spruce&quot;)) rownames(seg_models) &lt;- NULL seg_models ## forest_type intercept slope_pre slope_post years_detect years_recover ## 1 Douglas-Fir -0.1928642 -0.0013065 0.0081668 11.44996 36.89733 ## 2 Lodgepole Pine -0.1642223 -0.0013606 0.0123470 14.64341 29.55765 ## 3 Fir-Spruce -0.1617619 -0.0031520 0.0075947 19.37827 48.72007 ## adj_R2 ## 1 0.9552853 ## 2 0.8974964 ## 3 0.5804410 11.4.1.3 Plot ndvi_grouped_type &lt;- ndvi_grouped_type %&gt;% mutate(ptch_fr= case_when(ptch_fr == &quot;Lodegepole Pine&quot; ~ &quot;Lodgepole Pine&quot;, TRUE~ ptch_fr)) ggplot()+ geom_point(data = ndvi_grouped_type, aes(x= years_postfire,y = delta_ndvi,color = ptch_fr)) + geom_line(data= data_df,aes(x=years_postfire,y=fit),color = &quot;#F8766D&quot;) + geom_line(data= data_lp,aes(x=years_postfire,y=fit),color = &quot;#619CFF&quot;) + geom_line(data= data_fs,aes(x=years_postfire,y=fit),color = &quot;#00BA38&quot;) + labs(x=&quot;Years Post-Fire&quot;,y=&quot;dNDVI&quot;,color = &quot;Forest Type&quot;,title= &quot;NDVI Change Over Time 30 Years Post-Fire&quot;) + geom_hline(yintercept= 0,linetype=&quot;dashed&quot;,color=&quot;black&quot;,linewidth=1)+ annotate(&quot;text&quot;, x=12, y=0.015, label=&quot;Pre-Fire Snow-Cover NDVI&quot;)+ theme_bw()+ scale_x_continuous(breaks=seq(-5,30,5))+ scale_y_continuous(breaks=seq(-1,1,.05)) "],["landscape-level-conifer-recolonization.html", "Part 12 Landscape-Level Conifer Recolonization 12.1 Set Up 12.2 Calculate Patch Decomposition 12.3 Assess Proportion Reforested 12.4 Fragmentation 12.5 Plot", " Part 12 Landscape-Level Conifer Recolonization 12.1 Set Up 12.1.1 Libraries library(tidyverse) library(terra) library(sf) library(ggsankey) library(gridExtra) sf_use_s2(FALSE) 12.1.2 Import High-Severity Patches # fire list fire_list &lt;- c(&quot;Fire_7_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_31_1988&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_35_1989&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_42_1989&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_51_1991&quot;,&quot;Fire_54_1991&quot;,&quot;Fire_1_1988&quot;,&quot;Fire_2_1988&quot;,&quot;Fire_3_1988&quot;,&quot;Fire_4_1988&quot;) # import high-severity patches patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% mutate(Patch_ID = str_c(Fire_ID,&quot;-&quot;,1:n())) %&gt;% st_transform(crs = &quot;EPSG:4326&quot;) ## Reading layer `highsev_patches&#39; from data source ## `C:\\Users\\Casey\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\patches\\highsev_patches.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 5904 features and 10 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -118.6156 ymin: 42.57637 xmax: -106.96 ymax: 48.92836 ## Geodetic CRS: WGS 84 # set crs crs &lt;- crs(patches) 12.2 Calculate Patch Decomposition 12.2.1 Function to Track Patch Changes get_patches &lt;- function(fire_name){ print(fire_name) # select last timepoint&#39;s raster rast_fire &lt;- rast(str_c(&quot;data/prediction_rasters/&quot;,fire_name,&quot;_rf_t9.tif&quot;)) # use the high severity patches as t0 t0_patches &lt;- patches %&gt;% filter(Fire_ID == fire_name) %&gt;% dplyr::select(Fire_ID, Patch_ID,ecoregn,ptch_fr) %&gt;% mutate(t0_area = as.numeric(st_area(.))/10000) # convert the t9 raster to polygons t9_patches &lt;- as.polygons(rast_fire) %&gt;% st_as_sf() %&gt;% st_cast(to = &quot;POLYGON&quot;) %&gt;% st_transform(crs = crs) # join the t9 polygons to the original t0 patches to track decomposition conversion_df &lt;- st_join(t9_patches,t0_patches,left = TRUE,largest = TRUE) %&gt;% st_intersection(.,st_union(t0_patches))%&gt;% mutate(t9_area = as.numeric(st_area(.))/10000) %&gt;% st_drop_geometry() # export csv write_csv(conversion_df,str_c(&quot;data/patch_fate/&quot;,fire_name,&quot;.csv&quot;)) } 12.2.2 Apply Function to All Fires # get the decomposition df for each fire map(fire_list,get_patches) 12.2.3 Create Dataset for Each Forest Type # import and join all decomposition csvs patch_data &lt;- do.call(bind_rows,lapply(list.files(path = &quot;data/patch_fate/t0t9&quot;, pattern = &quot;_t0t9&quot;, all.files=TRUE, full.names=TRUE),read_csv)) # filter data to each forest type, and prepare data for alluvial plot patches_df &lt;- patch_data %&gt;% filter(ptch_fr == &quot;Douglas-Fir&quot;) %&gt;% make_long(t0_group,t9_group,value = t9_area) patches_df$node &lt;- factor(patches_df$node,levels = c(&quot;forested&quot;,&quot;0-50ha&quot;,&quot;50-100ha&quot;,&quot;100-500ha&quot;,&quot;500-1000ha&quot;,&quot;1000ha+&quot;)) patches_df$next_node &lt;- factor(patches_df$next_node,levels = c(&quot;forested&quot;,&quot;0-50ha&quot;,&quot;50-100ha&quot;,&quot;100-500ha&quot;,&quot;500-1000ha&quot;,&quot;1000ha+&quot;)) patches_df$value &lt;- as.numeric(patches_df$value) patches_lp &lt;- patch_data %&gt;% filter(ptch_fr == &quot;Lodegepole Pine&quot;)%&gt;% make_long(t0_group,t9_group,value = t9_area) patches_lp$node &lt;- factor(patches_lp$node,levels = c(&quot;forested&quot;,&quot;0-50ha&quot;,&quot;50-100ha&quot;,&quot;100-500ha&quot;,&quot;500-1000ha&quot;,&quot;1000ha+&quot;)) patches_lp$next_node &lt;- factor(patches_lp$next_node,levels = c(&quot;forested&quot;,&quot;0-50ha&quot;,&quot;50-100ha&quot;,&quot;100-500ha&quot;,&quot;500-1000ha&quot;,&quot;1000ha+&quot;)) patches_lp$value &lt;- as.numeric(patches_lp$value) patches_fs &lt;- patch_data %&gt;% filter(ptch_fr == &quot;Fir-Spruce&quot;)%&gt;% make_long(t0_group,t9_group,value = t9_area) patches_fs$node &lt;- factor(patches_fs$node,levels = c(&quot;forested&quot;,&quot;0-50ha&quot;,&quot;50-100ha&quot;,&quot;100-500ha&quot;,&quot;500-1000ha&quot;,&quot;1000ha+&quot;)) patches_fs$next_node &lt;- factor(patches_fs$next_node,levels = c(&quot;forested&quot;,&quot;0-50ha&quot;,&quot;50-100ha&quot;,&quot;100-500ha&quot;,&quot;500-1000ha&quot;,&quot;1000ha+&quot;)) patches_fs$value &lt;- as.numeric(patches_fs$value) 12.3 Assess Proportion Reforested 12.3.1 By Forest Type # percent of total area reforested by patch forest type patch_data$t0_group &lt;- factor(patch_data$t0_group,levels = c(&quot;0-50ha&quot;,&quot;50-100ha&quot;,&quot;100-500ha&quot;,&quot;500-1000ha&quot;,&quot;1000ha+&quot;)) patch_data_type &lt;- patch_data %&gt;% filter(ptch_fr %in% c(&quot;Fir-Spruce&quot;,&quot;Douglas-Fir&quot;,&quot;Lodegepole Pine&quot;)) %&gt;% dplyr::select(1:7) %&gt;% group_by(Patch_ID,t9_status,ptch_fr) %&gt;% summarize(t0_area = mean(t0_area), t9_area = sum(t9_area)) %&gt;% mutate(t9_status = case_when(t9_status == 1 ~ &quot;unforested&quot;, t9_status == 2 ~ &quot;forested&quot;)) %&gt;% filter(t9_status == &quot;forested&quot;)%&gt;% ungroup() %&gt;% group_by(ptch_fr) %&gt;% summarize(reforested_area_ha = sum(t9_area), burnt_area_ha = sum(t0_area), percent_reforested = round(reforested_area_ha/burnt_area_ha,2)) %&gt;% rename(forest_type = ptch_fr) patch_data_type ## # A tibble: 3  4 ## forest_type reforested_area_ha burnt_area_ha percent_reforested ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Douglas-Fir 13571. 17618. 0.77 ## 2 Fir-Spruce 27364. 62339. 0.44 ## 3 Lodegepole Pine 145866. 202032. 0.72 12.3.2 By Patch Size # percent of total area reforested by patch size class patch_data_size &lt;- patch_data %&gt;% filter(ptch_fr %in% c(&quot;Fir-Spruce&quot;,&quot;Douglas-Fir&quot;,&quot;Lodegepole Pine&quot;)) %&gt;% dplyr::select(1:7) %&gt;% group_by(Patch_ID,t9_status,t0_group) %&gt;% summarize(t0_area = mean(t0_area), t9_area = sum(t9_area)) %&gt;% mutate(t9_status = case_when(t9_status == 1 ~ &quot;unforested&quot;, t9_status == 2 ~ &quot;forested&quot;)) %&gt;% filter(t9_status == &quot;forested&quot;)%&gt;% ungroup() %&gt;% group_by(t0_group) %&gt;% summarize(reforested_area_ha = sum(t9_area), burnt_area_ha = sum(t0_area), percent_reforested = round(reforested_area_ha/burnt_area_ha,2)) %&gt;% rename(patch_size_class = t0_group) patch_data_size ## # A tibble: 5  4 ## patch_size_class reforested_area_ha burnt_area_ha percent_reforested ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0-50ha 21149. 30347. 0.7 ## 2 50-100ha 9872. 14126. 0.7 ## 3 100-500ha 29520. 45338. 0.65 ## 4 500-1000ha 20730. 30647. 0.68 ## 5 1000ha+ 105531. 161532. 0.65 12.4 Fragmentation ## function to identify the proportion of area that has moved to a smaller size class get_fragmentation &lt;- function(long_df,ftype){ frag &lt;- long_df %&gt;% drop_na() %&gt;% filter(next_node != &quot;forested&quot;) %&gt;% group_by(node,next_node) %&gt;% summarize(class_area = sum(value)) %&gt;% mutate(total_area = sum(class_area)) %&gt;% ungroup() %&gt;% mutate(percent_frag = class_area/total_area, ptch_fr = ftype) } # identify fragmentation separately across all three forest types frag_df &lt;- rbind(get_fragmentation(patches_lp,&quot;Lodgepole Pine&quot;), get_fragmentation(patches_fs,&quot;Fir-Spruce&quot;), get_fragmentation(patches_df,&quot;Douglas-fir&quot;)) %&gt;% filter(node !=&quot;0-50ha&quot;) no_frag &lt;- frag_df %&gt;% mutate(transition = node != next_node) %&gt;% group_by( ptch_fr,transition) %&gt;% summarize(transitioned_area = sum(class_area)) %&gt;% mutate(total_area = sum(transitioned_area), percent_transition = round(transitioned_area/total_area,2)) %&gt;% filter(transition == TRUE) %&gt;% rename(forest_type = ptch_fr) %&gt;% dplyr:: select(-transition) no_frag ## # A tibble: 3  4 ## # Groups: forest_type [3] ## forest_type transitioned_area total_area percent_transition ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Douglas-fir 2254. 2965. 0.76 ## 2 Fir-Spruce 14272. 28528. 0.5 ## 3 Lodgepole Pine 33096. 54257. 0.61 12.5 Plot 12.5.1 Alluvial Plot # prepare alluvial plots for each forest type # order by the node category patches_lp &lt;- patches_lp[order(patches_lp$next_node),] # used to block the forested patch flows from color set alphas2 &lt;- c(rep(0,2800),rep(0.8,8600)) # used to block unforested patch flows from the null color set colors &lt;- c(rep(&quot;gray&quot;,2800),rep(&quot;#fc8d59&quot;,8600)) alphas &lt;- c(rep(.4,2800),rep(0,8600)) plot_lp&lt;- ggplot(patches_lp, aes(x = x, next_x = next_x, node = node, next_node = next_node, fill = factor(node), label = node,value = value)) + geom_alluvial(flow.alpha = alphas2,width =.28)+# plots colored flows for the unforested patches geom_alluvial(flow.alpha = alphas,flow.fill=colors,width =.28) +# plots null flows for the forested patches geom_alluvial_text(size = 4, color = &quot;black&quot;) +# adds node label scale_fill_manual(values = c(&#39;#fef0d9&#39;,&#39;#fc8d59&#39;,&#39;#b30000&#39;,&#39;#fdcc8a&#39;,&#39;#e34a33&#39;,&quot;gray&quot;)) + # adds base node colors theme_alluvial(base_size = 14) +# sets font/plot size labs(x = NULL, y= NULL,title = &quot;Lodgepole Pine&quot;) +# labels theme(legend.position = &quot;none&quot;)+# remove legend title theme(axis.text.x = element_text(vjust = 6)) + # centers the plot title, adjust x axis labels scale_x_discrete(labels = c(&#39;0 Years\\nPost-Fire&#39;,&#39;30 Years\\nPost-Fire&#39;),expand = c(0, 0)) +# relabels the x axis names theme(panel.grid = element_blank(),panel.border = element_blank()) # remove excess white space patches_df &lt;- patches_df[order(patches_df$next_node),] alphas2 &lt;- c(rep(0,2800),rep(0.8,6200)) colors &lt;- c(rep(&quot;gray&quot;,2800),rep(&quot;#fc8d59&quot;,6200)) alphas &lt;- c(rep(.4,2800),rep(0,6200)) plot_df&lt;- ggplot(patches_df, aes(x = x, next_x = next_x, node = node, next_node = next_node, fill = factor(node), label = node,value = value)) + geom_alluvial(flow.alpha = alphas2,width =.28)+ geom_alluvial(flow.alpha = alphas,flow.fill=colors,width =.28) + geom_alluvial_text(size = 4, color = &quot;black&quot;) + scale_fill_manual(values = c(&#39;#fef0d9&#39;,&#39;#fc8d59&#39;,&#39;#b30000&#39;,&#39;#fdcc8a&#39;,&#39;#e34a33&#39;,&quot;gray&quot;)) + theme_alluvial(base_size = 14) + labs(x = NULL, y= NULL,title = &quot;Douglas-fir&quot;) + theme(legend.position = &quot;none&quot;) + theme(plot.subtitle = element_text(hjust = 0.5), axis.text.x = element_text(vjust = 6)) + scale_x_discrete(labels = c(&#39;0 Years\\nPost-Fire&#39;,&#39;30 Years\\nPost-Fire&#39;), expand = c(0, 0)) + theme(panel.grid = element_blank(), panel.border = element_blank()) patches_fs &lt;- patches_fs[order(patches_fs$next_node),] colors &lt;- c(rep(&quot;gray&quot;,2800),rep(&quot;#fc8d59&quot;,9200)) alphas &lt;- c(rep(.4,2800),rep(0,9200)) alphas2 &lt;- c(rep(0,2800),rep(0.8,9200)) plot_fs &lt;-ggplot(patches_fs, aes(x = x, next_x = next_x, node = node, next_node = next_node, fill = factor(node), label = node,value = value)) + geom_alluvial(flow.alpha = alphas2,width =.28)+ geom_alluvial(flow.alpha = alphas,flow.fill=colors,width =.28) + geom_alluvial_text(size = 4, color = &quot;black&quot;) + scale_fill_manual(values = c(&#39;#fef0d9&#39;,&#39;#fc8d59&#39;,&#39;#b30000&#39;,&#39;#fdcc8a&#39;,&#39;#e34a33&#39;,&quot;gray&quot;)) + theme_alluvial(base_size = 14) + labs(x = NULL, y= NULL,title = &quot;Fir-Spruce&quot;) + theme(legend.position = &quot;none&quot;) + theme(plot.subtitle = element_text(hjust = 0.5), axis.text.x = element_text(vjust = 6)) + scale_x_discrete(labels = c(&#39;0 Years\\nPost-Fire&#39;,&#39;30 Years\\nPost-Fire&#39;), expand = c(0, 0)) + theme(panel.grid = element_blank(), panel.border = element_blank()) 12.5.2 All Three Forest Types # plot the three plots together grid.arrange(plot_df,plot_lp,plot_fs,ncol=3, left = &quot;Total Patch Area (ha)&quot;) "],["patch-level-conifer-recolonization.html", "Part 13 Patch-Level Conifer Recolonization 13.1 Set Up 13.2 Calculate Landscape Patterns 13.3 Assess LSM Patterns", " Part 13 Patch-Level Conifer Recolonization 13.1 Set Up 13.1.1 Import Libraries library(sf) library(terra) library(mapview) library(raster) library(tidyverse) library(ggplot2) library(landscapemetrics) library(gridExtra) 13.1.2 Import Patch Polygons # fire list fire_list &lt;- c(&quot;Fire_54_1991&quot;,&quot;Fire_4_1988&quot;,&quot;Fire_7_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_31_1988&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_35_1989&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_42_1989&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_51_1991&quot;,&quot;Fire_1_1988&quot;,&quot;Fire_2_1988&quot;,&quot;Fire_3_1988&quot;) # import high-severity patches patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% mutate(Patch_ID = str_c(Fire_ID,&quot;-&quot;,1:n())) %&gt;% st_transform(crs = &quot;EPSG:4326&quot;) ## Reading layer `highsev_patches&#39; from data source ## `C:\\Users\\Casey\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\patches\\highsev_patches.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 5904 features and 10 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -118.6156 ymin: 42.57637 xmax: -106.96 ymax: 48.92836 ## Geodetic CRS: WGS 84 # patch metrics patch_metrics &lt;- read_csv(&quot;data/patches/patch_metrics.csv&quot;) 13.2 Calculate Landscape Patterns 13.2.1 Create Functions # function to apply landscape metrics across each fire event raster calc_lsm &lt;- function(fire_name){ # print patch ID print(fire_name) # filter to this specific patch patches_fire &lt;- patches %&gt;% filter(Fire_ID == fire_name) # import and name rasters for that fire rast_list &lt;- list.files(path = &quot;data/prediction_rasters&quot;, pattern = str_c(fire_name,&quot;_rf&quot;), all.files=TRUE, full.names=TRUE) rast_names &lt;- str_sub(rast_list,start = -6, end = -5) rast_fire &lt;- rast(rast_list) %&gt;% as.factor()%&gt;% terra::project(.,&quot;EPSG: 3857&quot;) names(rast_fire) &lt;- rast_names # apply lsm function to all patches within this fire event lsm_patchlist &lt;- lapply(unique(patches_fire$Patch_ID),get_patchlsm,patches_fire=patches_fire,rast_fire=rast_fire) # combine data lsm_df &lt;- do.call(rbind,lsm_patchlist) # export write_csv(lsm_df,str_c(&quot;data/lsm/&quot;,fire_name,&quot;.csv&quot;)) } # function to calculate landscape metrics of interest for each high-severity burn patch get_patchlsm &lt;- function(patch_name,patches_fire,rast_fire){ # filter to patch of interest print(patch_name) patch &lt;- patches_fire %&gt;% filter(Patch_ID==patch_name)%&gt;% st_transform(crs = &quot;EPSG: 3857&quot;) cropped_rast &lt;- crop(rast_fire,patch) masked_rast &lt;- mask(cropped_rast,patch) if(all(is.na(values(masked_rast))) == FALSE){ # calculate landscape metrics for this patch patch_lsm &lt;- calculate_lsm(masked_rast, what = c(&quot;lsm_c_pland&quot;,&quot;lsm_c_ca&quot;,&quot;lsm_c_tca&quot;,&quot;lsm_c_pladj&quot;,&quot;lsm_c_ed&quot;), count_boundary=TRUE, consider_boundary = TRUE, edge_depth = 3) %&gt;% mutate(Patch_ID = patch_name, ptch_fr=patch$ptch_fr, value = round(value,3)) return(patch_lsm) } else {masked_rast print(&quot;empty&quot;) } } 13.2.2 Map Across All Fires # map landscape metrics functions across all fires map(fire_list,calc_lsm) 13.3 Assess LSM Patterns 13.3.1 Prepare Data # combine lsm csvs lsm_big &lt;- lapply(list.files(path = &quot;data/lsm&quot;, pattern = str_c(&quot;Fire&quot;), all.files=TRUE, full.names=TRUE),read_csv) %&gt;% do.call(rbind,.) %&gt;% mutate(timepoint = str_c(&quot;t&quot;,layer), condition = case_when(class == 1 ~ &quot;unforested&quot;, TRUE ~ &quot;forested&quot;)) %&gt;% dplyr::select(Patch_ID, ptch_fr,timepoint,condition,metric,value) # clean up dataframe lsm_df &lt;- lsm_big %&gt;% filter(Patch_ID != &quot;empty&quot;, timepoint != &quot;t1&quot;) %&gt;% pivot_wider(names_from = metric,values_from = value,values_fn = as.numeric) %&gt;% rename(core_area = tca, total_area = ca, edge_area_ratio = ed, perc_like_adj = pladj, perc_area = pland) %&gt;% mutate(perc_core = round(core_area/total_area,4)*100, time_yr = as.factor(case_when( timepoint == &quot;t2&quot; ~ 5, timepoint == &quot;t3&quot; ~ 8, timepoint == &quot;t4&quot; ~ 11, timepoint == &quot;t5&quot; ~ 14, timepoint == &quot;t6&quot; ~ 17, timepoint == &quot;t7&quot; ~ 20, timepoint == &quot;t8&quot; ~ 23, timepoint == &quot;t9&quot; ~ 26, timepoint == &quot;t10&quot; ~ 29))) forested_df &lt;- lsm_df %&gt;% filter(condition == &quot;forested&quot;) unforested_df &lt;- lsm_df %&gt;% filter(condition == &quot;unforested&quot;) 13.3.2 Patch-Level Area Reforested # calculate the proportion of area that is reforested through time forested_df_sum &lt;- forested_df %&gt;% group_by(ptch_fr,time_yr) %&gt;% summarize(perc_area = median(perc_area,na.rm = TRUE)) ## `summarise()` has grouped output by &#39;ptch_fr&#39;. You can override using the ## `.groups` argument. # calculate the median and spread of patch-level recolonization by forest type reforested_spread &lt;- forested_df %&gt;% filter(timepoint == &quot;t10&quot;, ptch_fr %in% c(&quot;Douglas-Fir&quot;,&quot;Lodegepole Pine&quot;,&quot;Fir-Spruce&quot;)) %&gt;% group_by(ptch_fr) %&gt;% summarize(IQR = IQR (perc_area), median = median(perc_area)) %&gt;% rename(forest_type = ptch_fr) reforested_spread ## # A tibble: 3  3 ## forest_type IQR median ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Douglas-Fir 46.3 91.1 ## 2 Fir-Spruce 62.3 41.3 ## 3 Lodegepole Pine 9.80 100 # create boxplots showing the distribution of patch-level reoccupancy by forest type pland_df &lt;- ggplot(forested_df %&gt;% filter(ptch_fr==&quot;Douglas-Fir&quot;),aes(time_yr,perc_area)) + geom_boxplot(outlier.shape = NA,fill = &quot;#F8766D&quot;) + geom_smooth(data=forested_df_sum%&gt;% filter(ptch_fr==&quot;Douglas-Fir&quot;), aes(as.numeric(time_yr),perc_area), linetype = &quot;dashed&quot;,color = &quot;black&quot;,na.rm = TRUE)+ labs(x=&quot;Years Post-Fire&quot;,fill=&quot;Forest Type&quot;,y=NULL,title = &quot;Douglas-Fir&quot;) + theme_classic() + scale_y_continuous(breaks = c(0,20,40,60,80,100),limits = c(-10,110)) pland_lp &lt;-ggplot(forested_df %&gt;% filter(ptch_fr==&quot;Lodegepole Pine&quot;),aes(time_yr,perc_area)) + geom_boxplot(outlier.shape = NA,fill =&quot;#619CFF&quot;) + geom_smooth(data=forested_df_sum%&gt;% filter(ptch_fr==&quot;Lodegepole Pine&quot;), aes(as.numeric(time_yr),perc_area,ymin =0,ymax=100), linetype = &quot;dashed&quot;,color = &quot;black&quot;,na.rm = TRUE) + labs(x=&quot;Years Post-Fire&quot;,fill=&quot;Forest Type&quot;,y=NULL,title = &quot;Lodgepole Pine&quot;) + theme_classic() + scale_y_continuous(breaks = c(0,20,40,60,80,100),limits = c(-10,110)) pland_fs &lt;- ggplot(forested_df %&gt;% filter(ptch_fr==&quot;Fir-Spruce&quot;),aes(time_yr,perc_area)) + geom_boxplot(outlier.shape = NA,fill = &quot;#00BA38&quot;) + geom_smooth(data=forested_df_sum%&gt;% filter(ptch_fr==&quot;Fir-Spruce&quot;), aes(as.numeric(time_yr),perc_area), linetype = &quot;dashed&quot;,color = &quot;black&quot;,na.rm = TRUE)+ labs(x=&quot;Years Post-Fire&quot;,fill=&quot;Forest Type&quot;,y=NULL,title = &quot;Fir-Spruce&quot;) + #title = &quot;Fir-Spruce&quot;,y = &quot;Percent of Patch Occupied by Conifers&quot;, theme_classic() + scale_y_continuous(breaks = c(0,20,40,60,80,100),limits = c(-10,110)) grid.arrange(pland_df,pland_lp,pland_fs,ncol=3, left = &quot;Percent of Patch Occupied by Conifers&quot;) "],["conifer-expansion-patterns.html", "Part 14 Conifer Expansion Patterns 14.1 Set Up 14.2 Calculate Landscape Patterns 14.3 Assess LEI Patterns 14.4 Plot LEI and AWMEI", " Part 14 Conifer Expansion Patterns 14.1 Set Up 14.1.1 Import Libraries library(sf) library(terra) library(raster) library(tidyverse) library(ggplot2) library(exactextractr) library(gridExtra) library(grid) 14.1.2 Import Patch Polygons # fire list fire_list &lt;- c(&quot;Fire_54_1991&quot;,&quot;Fire_4_1988&quot;,&quot;Fire_7_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_31_1988&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_35_1989&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_42_1989&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_51_1991&quot;,&quot;Fire_1_1988&quot;,&quot;Fire_3_1988&quot;,&quot;Fire_2_1988&quot;) # import high-severity patches patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% mutate(Patch_ID = str_c(Fire_ID,&quot;-&quot;,1:n())) %&gt;% st_transform(crs = &quot;EPSG:4326&quot;) ## Reading layer `highsev_patches&#39; from data source ## `C:\\Users\\Casey\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\patches\\highsev_patches.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 5904 features and 10 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -118.6156 ymin: 42.57637 xmax: -106.96 ymax: 48.92836 ## Geodetic CRS: WGS 84 # set crs crs &lt;- crs(patches) 14.2 Calculate Landscape Patterns # function to set up rasters to calculate for each fire event get_growthlei &lt;- function(fire_name){ # print fire ID print(fire_name) # filter to this specific fire patches_fire &lt;- patches %&gt;% dplyr::filter(Fire_ID == fire_name)%&gt;% st_transform(3488) # import and name rasters for that fire rast_list &lt;- list.files(path = &quot;data/prediction_rasters&quot;, pattern = str_c(fire_name,&quot;_rf&quot;), all.files=TRUE, full.names=TRUE) rast_names &lt;- str_sub(rast_list,start = -6, end = -5) rast_fire &lt;- rast(rast_list) names(rast_fire) &lt;- rast_names loop_names &lt;- rast_names[2:10] lapply(loop_names, get_leitimesteps, rast_fire=rast_fire,patches_fire=patches_fire,fire_name = fire_name) } # function to create LEI dataset for each fire&#39;s time steps get_leitimesteps &lt;- function(rast_name,rast_fire,patches_fire,fire_name){ print(rast_name) # select the timepoint and corresponding raster timepoint2 &lt;- rast_name timepoint2_raster &lt;- rast_fire[[timepoint2]] %&gt;% as.factor() # set up raster for the previous timepoint timepoint1 &lt;- str_c(&quot;t&quot;,as.numeric(str_sub(timepoint2,2,2))-1) timepoint1_raster &lt;- rast_fire[[timepoint1]] %&gt;% as.factor() # set area outside of patches to presence timepoint1_raster[is.na(timepoint1_raster)] &lt;- 2 # difference the two time points to identify areas of change timepoint_difference_raster &lt;- timepoint2_raster - timepoint1_raster # convert areas of new presence to polgyons timepoint_difference_polys &lt;- as.polygons(timepoint_difference_raster) %&gt;% st_as_sf() %&gt;% st_cast(&quot;POLYGON&quot;) %&gt;% filter(.[[1]] == 1) %&gt;% st_transform(3488)%&gt;% st_join(.,st_make_valid(patches_fire),largest=TRUE) # in case there is no growth for this time period... if(nrow(timepoint_difference_polys)==0){ print(&quot;no polys&quot;) }else{ print(length(unique(timepoint_difference_polys$newgrowth_id))) # prepare the differenced polygon dataset timepoint_difference_polys &lt;- timepoint_difference_polys %&gt;% mutate(newgrowth_area_ha = round(as.numeric(st_area(geometry))/10000,3), newgrowth_id = str_c(Patch_ID,&quot;_&quot; ,rast_name,&quot;_polygon&quot;,c(1:nrow(.)))) # apply function calculate lei for each new growth polygon lei_list &lt;- lapply(unique(timepoint_difference_polys$newgrowth_id), get_timepointpolys, timepoint_difference_polys=timepoint_difference_polys,timepoint1_raster=timepoint1_raster,rast_name=rast_name) # combine data lei_df &lt;- do.call(rbind,lei_list) # export to csv write_csv(lei_df,str_c(&quot;data/lei/&quot;,fire_name,&quot;-&quot;,rast_name,&quot;.csv&quot;)) } } # function to calculate lei for each new growth polygon get_timepointpolys &lt;- function(newgrowth_name,timepoint_difference_polys,timepoint1_raster,rast_name) { print(newgrowth_name) # select the polygon of interest newgrowth &lt;- timepoint_difference_polys %&gt;% filter(newgrowth_id == newgrowth_name) # create 100m ring around each polygon (dispersal distance) newgrowth_buffer &lt;- st_buffer(newgrowth,100) newgrowth_ring &lt;- st_difference(newgrowth_buffer, newgrowth) # extract the previous raster presence/absence values from the ring area lei_full &lt;- do.call(rbind,exact_extract(timepoint1_raster,newgrowth_ring %&gt;% st_transform(4326),include_cols = TRUE)) # create dataset for each new growth polygon, calculate and categorize lei values lei &lt;- lei_full[1:length(lei_full$Fire_ID),] %&gt;% group_by(newgrowth_id,value) %&gt;% summarize(frac=sum(coverage_fraction)) %&gt;% mutate(timepoint = rast_name, lei = frac/sum(frac), lei_category = case_when(lei &gt; 0.5 ~ &quot;infill&quot;, lei &lt; .01 ~ &quot;leapfrog&quot;, TRUE ~ &quot;expansion&quot;)) %&gt;% filter(value == 2) %&gt;% left_join(.,timepoint_difference_polys,by = &quot;newgrowth_id&quot;)%&gt;% dplyr::select(newgrowth_id,timepoint,lei,lei_category,Fire_ID,Patch_ID,ptch_fr,newgrowth_area_ha) return(lei) } # apply to all fires map(fire_list,get_growthlei) 14.3 Assess LEI Patterns 14.3.1 Arrange Data # assemble all lei csv files lei_patch &lt;- lapply(list.files(path = &quot;data/lei&quot;, pattern = str_c(&quot;Fire&quot;), all.files=TRUE, full.names=TRUE),read_csv) %&gt;% do.call(rbind,.) 14.3.2 LEI and AMWEI Datasets # calculate the AMWEI for each forest type through time patchwise_lei &lt;- lei_patch %&gt;% mutate(scaled_lei = lei * newgrowth_area_ha) %&gt;% group_by(ptch_fr,timepoint) %&gt;% summarize(lei = 100*sum(scaled_lei)/sum(newgrowth_area_ha)) %&gt;% filter(ptch_fr %in% c(&quot;Douglas-Fir&quot;,&quot;Fir-Spruce&quot;,&quot;Lodegepole Pine&quot;)) %&gt;% mutate(timepoint = as.numeric(str_sub(timepoint,2,2))) %&gt;% ungroup() %&gt;% mutate(tp = timepoint*3+2, ptch_fr= case_when(ptch_fr == &quot;Lodegepole Pine&quot; ~ &quot;Lodgepole Pine&quot;, TRUE~ ptch_fr)) # calculate the area of growth for each forest type through time lei_totalarea &lt;- lei_patch %&gt;% group_by(timepoint,ptch_fr) %&gt;% summarize(area = sum(newgrowth_area_ha), n=n()) %&gt;% filter(ptch_fr %in% c(&quot;Douglas-Fir&quot;,&quot;Fir-Spruce&quot;,&quot;Lodegepole Pine&quot;)) # scale the area at each timepoint by the total reforested area lei_totalarea_scaled &lt;- lei_totalarea %&gt;% mutate(scaled_area= case_when(ptch_fr == &quot;Lodegepole Pine&quot; ~ area/195158.96, ptch_fr == &quot;Fir-Spruce&quot; ~ area/57385.80, ptch_fr == &quot;Douglas-Fir&quot; ~ area/19321.15), timepoint = as.numeric(str_sub(timepoint,2,2)), tp = timepoint*3+2, ptch_fr= case_when(ptch_fr == &quot;Lodegepole Pine&quot; ~ &quot;Lodgepole Pine&quot;, TRUE~ ptch_fr)) # calculate the area of each LEI growth pattern for each forest type lei_growth &lt;- lei_patch %&gt;% group_by(ptch_fr, timepoint, lei_category) %&gt;% summarize(n = n(), area = sum(newgrowth_area_ha))%&gt;% mutate(n_perc = round(n/sum(n),2), area_perc = round(area/sum(area),2), growth_size = area/n) %&gt;% filter(ptch_fr %in% c(&quot;Douglas-Fir&quot;,&quot;Fir-Spruce&quot;,&quot;Lodegepole Pine&quot;)) 14.4 Plot LEI and AWMEI ggplot(lei_totalarea_scaled,aes(tp,scaled_area*100,color= ptch_fr,group=ptch_fr))+ geom_point()+ geom_smooth(se = FALSE,method = &quot;loess&quot;)+ labs(color = &quot;Forest Type&quot;,y = &quot;Percent of Reoccupied Area (%)&quot;,x=&quot;Years Post-Fire&quot;,title=&quot;Timeline of New Growth Identification by Forest Type&quot;)+ theme_bw() + scale_x_continuous(breaks=seq(0,30,5))+ scale_y_continuous(breaks=seq(0,30,5))+ coord_fixed(ratio = 1) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ggplot(patchwise_lei,aes(tp,lei,color = ptch_fr,group = ptch_fr))+ geom_point() + geom_smooth(se = FALSE, method = &quot;lm&quot;) + theme_bw() + labs(y = &quot;AMWEI&quot;,x = &quot;Years Post-Fire&quot;, color = &quot;Forest Type&quot;,title=&quot;Area Weighted Mean Expansion Index by Forest Type&quot;)+ scale_x_continuous(breaks=seq(0,30,5))+ scale_y_continuous(breaks=seq(30,70,5))+ geom_hline(yintercept = 50,linetype = &quot;dashed&quot;)+ coord_fixed(ratio = .66)+ scale_fill_discrete(labels=c(&quot;Douglas-Fir&quot;, &quot;Fir-Spruce&quot;,&quot;Lodgepole Pine&quot; )) ## `geom_smooth()` using formula = &#39;y ~ x&#39; "],["recovery-likelihood.html", "Part 15 Recovery Likelihood 15.1 Set Up 15.2 Prepare Patch Data 15.3 Model Patch Recovery", " Part 15 Recovery Likelihood 15.1 Set Up 15.1.1 Libraries library(tidyverse) library(terra) library(sf) library(gridExtra) library(car) library(exactextractr) library(elevatr) library(rms) library(rempsyc) sf_use_s2(FALSE) 15.1.2 Import High-Severity Patches # fire list fire_list &lt;- c(&quot;Fire_7_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_31_1988&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_35_1989&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_42_1989&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_51_1991&quot;,&quot;Fire_54_1991&quot;,&quot;Fire_1_1988&quot;,&quot;Fire_2_1988&quot;,&quot;Fire_3_1988&quot;,&quot;Fire_4_1988&quot;) # import high-severity patches patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% mutate(Patch_ID = str_c(Fire_ID,&quot;-&quot;,1:n())) %&gt;% st_transform(crs = &quot;EPSG:4326&quot;) ## Reading layer `highsev_patches&#39; from data source ## `C:\\Users\\Casey\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\patches\\highsev_patches.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 5904 features and 10 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -118.6156 ymin: 42.57637 xmax: -106.96 ymax: 48.92836 ## Geodetic CRS: WGS 84 # set crs crs &lt;- crs(patches) 15.2 Prepare Patch Data 15.2.1 Calculate Percent Reforested # import and join patch fragmentation data patch_fragmentation &lt;- do.call(bind_rows,lapply(list.files(path = &quot;data/patch_fate/t0t9&quot;, pattern = &quot;t0t9&quot;, all.files=TRUE, full.names=TRUE),read_csv)) # calculate the proportion of area recolonized by conifers after 30 years patch_recovery &lt;- patch_fragmentation %&gt;% group_by(Patch_ID,t9_status) %&gt;% summarise(t0_area = mean(t0_area), t9_area = round(sum(t9_area),5))%&gt;% pivot_wider(values_from = t9_area,names_from=t9_status) %&gt;% rename(t9_area_unforested = 4, t9_area_forested = 3)%&gt;% replace(is.na(.), 0) %&gt;% mutate(perc_forested = t9_area_forested/(t0_area)) 15.2.2 Calculate Patch Area and Edge patch_metrics &lt;- patches %&gt;% dplyr::select(Fire_ID,Patch_ID,ptch_fr,ecoregn) %&gt;% st_transform(3488) %&gt;% mutate(patch_area = round(as.numeric(st_area(.))/10000,4), perim_m = as.numeric(round(st_length(st_cast(geometry,to = &quot;MULTILINESTRING&quot;)),4)), area_perim_rat = patch_area/perim_m) %&gt;% st_buffer(-100) %&gt;% mutate(core_area = round(as.numeric(st_area(.))/10000,4), perc_core = round(core_area / patch_area,5))%&gt;% st_drop_geometry() 15.2.3 Calculate Patch Climate # import terraclim climate data, 3 year means before fire event # for each patch, extract the mean value for each climate variable get_climate &lt;- function(var){ extracted_var &lt;- list.files(path = &quot;data/terraclim/&quot;, pattern = var, all.files=TRUE, full.names=TRUE) %&gt;% rast() %&gt;% mean() %&gt;% extract(.,patches %&gt;% st_transform(crs= crs(.)),fun = mean,weights = TRUE, exact = TRUE) %&gt;% dplyr::select(mean) colnames(extracted_var) &lt;- var return(extracted_var) } # list of climate variables climate_variables &lt;- c(&quot;def&quot;,&quot;pdsi&quot;,&quot;swe&quot;,&quot;ppt&quot;,&quot;pet&quot;,&quot;tmax&quot;,&quot;soil&quot;,&quot;vpd&quot;) # extract mean climate values for each patch and assign to patch ID climate_df &lt;- map(climate_variables,get_climate) ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= patch_climate &lt;- do.call(cbind,climate_df) %&gt;% cbind(Patch_ID = patches$Patch_ID,.) 15.2.4 Calculate Latitude patch_latitude &lt;- patches %&gt;% mutate(latitude = st_coordinates(st_centroid(geometry))[,2]) %&gt;% dplyr:: select(Patch_ID, latitude) %&gt;% st_drop_geometry() 15.2.5 Calculate Topography extract_topo &lt;- function(fire_name){ print(paste0(&quot;Starting Fire &quot;,fire_name)) # filter the patches for this fire fire_patches &lt;- patches %&gt;% filter(Fire_ID==fire_name) %&gt;% st_transform(crs=4326) dem &lt;- get_elev_raster(fire_patches,z=11) aspect &lt;- terrain(dem, opt = &quot;aspect&quot;,unit = &quot;degrees&quot;) slope &lt;- terrain(dem,opt=&#39;slope&#39;, unit=&#39;degrees&#39;) ccaspect &lt;- cos(aspect) # get the mean topographic values for each patch in this fire extracted_elev &lt;- left_join(fire_patches, exact_extract(dem,fire_patches, append_cols = TRUE, max_cells_in_memory = 3e+08, fun = &quot;mean&quot;)) %&gt;% st_drop_geometry() %&gt;% rename(elevation = mean) %&gt;% dplyr::select(Patch_ID, elevation) extracted_aspect &lt;- left_join(fire_patches, exact_extract(ccaspect,fire_patches, append_cols = TRUE, max_cells_in_memory = 3e+08, fun = &quot;mean&quot;)) %&gt;% st_drop_geometry() %&gt;% rename(aspect = mean) %&gt;% dplyr::select(aspect) extracted_slope &lt;- left_join(fire_patches, exact_extract(slope,fire_patches, append_cols = TRUE, max_cells_in_memory = 3e+08, fun = &quot;mean&quot;)) %&gt;% st_drop_geometry() %&gt;% rename(slope = mean) %&gt;% dplyr::select(slope) extracted_data &lt;- cbind(extracted_elev,extracted_aspect,extracted_slope) # export return(extracted_data) } # map extraction function across all fires extracted_fires &lt;- map(fire_list,extract_topo) patch_topography &lt;- do.call(rbind,extracted_fires) 15.2.6 Join Patch Metrics and Recovery Data # combine all predictor datasets, set recovery threshold to 80% forested log_recovery &lt;- list(patch_metrics,patch_recovery,patch_latitude,patch_climate,patch_topography) %&gt;% reduce(full_join, by=&#39;Patch_ID&#39;) %&gt;% drop_na() %&gt;% filter(ptch_fr %in% c(&quot;Douglas-Fir&quot;,&quot;Lodegepole Pine&quot;,&quot;Fir-Spruce&quot;)) %&gt;% mutate(log_recovered = case_when(perc_forested &gt;= 0.8 ~ 1, perc_forested &lt; 0.8 ~ 0), area_perim_rat = area_perim_rat*10000, ecoregn = as.factor(ecoregn), ptch_fr= as.factor(ptch_fr)) %&gt;% st_drop_geometry() 15.3 Model Patch Recovery 15.3.1 Prepare Model Data # data prep required for lrm model dd &lt;- datadist(log_recovery) options(datadist=&quot;dd&quot;) 15.3.2 Create Logistic Model # logistic regression model with lrm log_model &lt;- lrm(log_recovered ~ ptch_fr + area_perim_rat + patch_area + elevation + slope + aspect + def + swe ,data = log_recovery) log_model ## Logistic Regression Model ## ## lrm(formula = log_recovered ~ ptch_fr + area_perim_rat + patch_area + ## elevation + slope + aspect + def + swe, data = log_recovery) ## ## Model Likelihood Discrimination Rank Discrim. ## Ratio Test Indexes Indexes ## Obs 3852 LR chi2 1690.54 R2 0.477 C 0.858 ## 0 1653 d.f. 9 R2(9,3852)0.354 Dxy 0.716 ## 1 2199 Pr(&gt; chi2) &lt;0.0001 R2(9,2831)0.448 gamma 0.716 ## max |deriv| 3e-06 Brier 0.147 tau-a 0.351 ## ## Coef S.E. Wald Z Pr(&gt;|Z|) ## Intercept 9.1804 0.7289 12.59 &lt;0.0001 ## ptch_fr=Fir-Spruce -0.7437 0.1708 -4.35 &lt;0.0001 ## ptch_fr=Lodegepole Pine 1.0070 0.1679 6.00 &lt;0.0001 ## area_perim_rat -0.0070 0.0019 -3.69 0.0002 ## patch_area -0.0001 0.0001 -1.55 0.1219 ## elevation -0.0031 0.0002 -15.13 &lt;0.0001 ## slope -0.0993 0.0069 -14.37 &lt;0.0001 ## aspect -0.1738 0.4785 -0.36 0.7164 ## def -0.0231 0.0113 -2.05 0.0404 ## swe 0.0066 0.0034 1.97 0.0491 15.3.3 Odds Ratios # odds ratio summary(log_model) ## Effects Response : log_recovered ## ## Factor Low High Diff. ## area_perim_rat 30.272000 51.63800 21.366000 ## Odds Ratio 30.272000 51.63800 21.366000 ## patch_area 3.416200 18.02000 14.604000 ## Odds Ratio 3.416200 18.02000 14.604000 ## elevation 2267.700000 2596.70000 328.980000 ## Odds Ratio 2267.700000 2596.70000 328.980000 ## slope 6.480900 19.04800 12.567000 ## Odds Ratio 6.480900 19.04800 12.567000 ## aspect -0.047218 0.04535 0.092568 ## Odds Ratio -0.047218 0.04535 0.092568 ## def 17.771000 22.01700 4.245500 ## Odds Ratio 17.771000 22.01700 4.245500 ## swe 66.483000 89.78600 23.303000 ## Odds Ratio 66.483000 89.78600 23.303000 ## ptch_fr - Douglas-Fir:Lodegepole Pine 3.000000 1.00000 NA ## Odds Ratio 3.000000 1.00000 NA ## ptch_fr - Fir-Spruce:Lodegepole Pine 3.000000 2.00000 NA ## Odds Ratio 3.000000 2.00000 NA ## Effect S.E. Lower 0.95 Upper 0.95 ## -0.1498300 0.04061000 -0.2294300 -0.07023900 ## 0.8608500 NA 0.7949900 0.93217000 ## -0.0014748 0.00095351 -0.0033436 0.00039406 ## 0.9985300 NA 0.9966600 1.00040000 ## -1.0189000 0.06734300 -1.1509000 -0.88692000 ## 0.3609900 NA 0.3163500 0.41192000 ## -1.2475000 0.08678400 -1.4176000 -1.07740000 ## 0.2872200 NA 0.2423000 0.34048000 ## -0.0160870 0.04429000 -0.1028900 0.07071900 ## 0.9840400 NA 0.9022200 1.07330000 ## -0.0981640 0.04789700 -0.1920400 -0.00428820 ## 0.9065000 NA 0.8252700 0.99572000 ## 0.1542000 0.07837000 0.0005946 0.30780000 ## 1.1667000 NA 1.0006000 1.36040000 ## -1.0070000 0.16789000 -1.3361000 -0.67800000 ## 0.3653000 NA 0.2628700 0.50763000 ## -1.7507000 0.09654400 -1.9400000 -1.56150000 ## 0.1736500 NA 0.1437100 0.20982000 15.3.4 Make Odds Ratio Table # bring in odds ratio table odds_table &lt;- read_csv(&quot;data/recovery/oddsratios_lrm.csv&quot;) %&gt;% dplyr::select(-6,-7,-8,-9,-12) # function to show data to correct number of digits fun &lt;- function(x) {formatC(x, format = &quot;f&quot;, digits = 3)} # create table odds &lt;- nice_table(odds_table, separate.header = TRUE,width = 1,col.format.custom = c(4,6),format.custom = &quot;fun&quot;) # export to word flextable::save_as_docx(odds, path = &quot;data/recovery/odds_table.docx&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
